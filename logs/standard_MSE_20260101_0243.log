2026-01-01 02:43:43,264 [root] [INFO] using device: cuda
2026-01-01 02:43:55,706 [training] [INFO] training_size: 130527, testing_size: 14502
2026-01-01 02:43:57,691 [training] [INFO] start training epochs 1
2026-01-01 02:44:04,260 [training] [INFO] training steps: 100, Loss: 6.2611
2026-01-01 02:44:09,057 [training] [INFO] training steps: 200, Loss: 3.7984
2026-01-01 02:44:13,852 [training] [INFO] training steps: 300, Loss: 2.1681
2026-01-01 02:44:18,579 [training] [INFO] training steps: 400, Loss: 1.6806
2026-01-01 02:44:23,328 [training] [INFO] training steps: 500, Loss: 1.4857
2026-01-01 02:44:23,913 [training] [INFO] epoch 1 train loss:8.197470481722963
2026-01-01 02:44:25,262 [training] [INFO] epoch 1 test loss:1.4088
2026-01-01 02:44:25,262 [training] [INFO] start training epochs 2
2026-01-01 02:44:30,117 [training] [INFO] training steps: 600, Loss: 2.4309
2026-01-01 02:44:34,894 [training] [INFO] training steps: 700, Loss: 1.7865
2026-01-01 02:44:39,671 [training] [INFO] training steps: 800, Loss: 2.2255
2026-01-01 02:44:44,447 [training] [INFO] training steps: 900, Loss: 3.3779
2026-01-01 02:44:49,221 [training] [INFO] training steps: 1000, Loss: 2.0181
2026-01-01 02:44:50,207 [training] [INFO] epoch 2 train loss:1.9074975009058035
2026-01-01 02:44:51,519 [training] [INFO] epoch 2 test loss:1.7213
2026-01-01 02:44:51,520 [training] [INFO] start training epochs 3
2026-01-01 02:44:55,883 [training] [INFO] training steps: 1100, Loss: 1.1071
2026-01-01 02:45:00,651 [training] [INFO] training steps: 1200, Loss: 1.5013
2026-01-01 02:45:05,419 [training] [INFO] training steps: 1300, Loss: 1.4302
2026-01-01 02:45:10,191 [training] [INFO] training steps: 1400, Loss: 0.9123
2026-01-01 02:45:14,966 [training] [INFO] training steps: 1500, Loss: 1.0267
2026-01-01 02:45:16,429 [training] [INFO] epoch 3 train loss:1.444088194767634
2026-01-01 02:45:17,741 [training] [INFO] epoch 3 test loss:1.1337
2026-01-01 02:45:17,742 [training] [INFO] start training epochs 4
2026-01-01 02:45:21,633 [training] [INFO] training steps: 1600, Loss: 1.3391
2026-01-01 02:45:26,402 [training] [INFO] training steps: 1700, Loss: 1.0319
2026-01-01 02:45:31,183 [training] [INFO] training steps: 1800, Loss: 1.4359
2026-01-01 02:45:35,961 [training] [INFO] training steps: 1900, Loss: 1.3403
2026-01-01 02:45:40,732 [training] [INFO] training steps: 2000, Loss: 0.9284
2026-01-01 02:45:42,675 [training] [INFO] epoch 4 train loss:1.288447960100922
2026-01-01 02:45:43,993 [training] [INFO] epoch 4 test loss:1.0728
2026-01-01 02:45:43,993 [training] [INFO] start training epochs 5
2026-01-01 02:45:47,430 [training] [INFO] training steps: 2100, Loss: 0.7445
2026-01-01 02:45:52,211 [training] [INFO] training steps: 2200, Loss: 1.3585
2026-01-01 02:45:56,988 [training] [INFO] training steps: 2300, Loss: 1.5148
2026-01-01 02:46:01,772 [training] [INFO] training steps: 2400, Loss: 0.8026
2026-01-01 02:46:06,554 [training] [INFO] training steps: 2500, Loss: 1.0286
2026-01-01 02:46:08,982 [training] [INFO] epoch 5 train loss:1.0956663648287455
2026-01-01 02:46:10,324 [training] [INFO] epoch 5 test loss:1.4035
2026-01-01 02:46:10,324 [training] [INFO] start training epochs 6
2026-01-01 02:46:13,272 [training] [INFO] training steps: 2600, Loss: 1.2719
2026-01-01 02:46:18,054 [training] [INFO] training steps: 2700, Loss: 0.7107
2026-01-01 02:46:22,825 [training] [INFO] training steps: 2800, Loss: 0.8083
2026-01-01 02:46:27,604 [training] [INFO] training steps: 2900, Loss: 1.3853
2026-01-01 02:46:32,375 [training] [INFO] training steps: 3000, Loss: 0.8370
2026-01-01 02:46:35,268 [training] [INFO] epoch 6 train loss:1.0405476220682555
2026-01-01 02:46:36,586 [training] [INFO] epoch 6 test loss:0.8047
2026-01-01 02:46:36,587 [training] [INFO] start training epochs 7
2026-01-01 02:46:39,054 [training] [INFO] training steps: 3100, Loss: 0.9305
2026-01-01 02:46:43,806 [training] [INFO] training steps: 3200, Loss: 0.9716
2026-01-01 02:46:48,565 [training] [INFO] training steps: 3300, Loss: 0.8172
2026-01-01 02:46:53,324 [training] [INFO] training steps: 3400, Loss: 0.9571
2026-01-01 02:46:58,084 [training] [INFO] training steps: 3500, Loss: 0.7741
2026-01-01 02:47:01,447 [training] [INFO] epoch 7 train loss:0.9347828268420463
2026-01-01 02:47:02,775 [training] [INFO] epoch 7 test loss:1.0463
2026-01-01 02:47:02,776 [training] [INFO] start training epochs 8
2026-01-01 02:47:04,758 [training] [INFO] training steps: 3600, Loss: 0.8286
2026-01-01 02:47:09,565 [training] [INFO] training steps: 3700, Loss: 1.1567
2026-01-01 02:47:14,367 [training] [INFO] training steps: 3800, Loss: 1.0441
2026-01-01 02:47:19,201 [training] [INFO] training steps: 3900, Loss: 0.7287
2026-01-01 02:47:24,044 [training] [INFO] training steps: 4000, Loss: 0.9104
2026-01-01 02:47:27,932 [training] [INFO] epoch 8 train loss:0.9136519787942662
2026-01-01 02:47:29,269 [training] [INFO] epoch 8 test loss:0.8408
2026-01-01 02:47:29,269 [training] [INFO] start training epochs 9
2026-01-01 02:47:30,786 [training] [INFO] training steps: 4100, Loss: 0.9029
2026-01-01 02:47:35,598 [training] [INFO] training steps: 4200, Loss: 1.1173
2026-01-01 02:47:40,419 [training] [INFO] training steps: 4300, Loss: 0.5876
2026-01-01 02:47:45,233 [training] [INFO] training steps: 4400, Loss: 0.9552
2026-01-01 02:47:50,036 [training] [INFO] training steps: 4500, Loss: 0.7521
2026-01-01 02:47:54,380 [training] [INFO] epoch 9 train loss:0.8488132465703815
2026-01-01 02:47:55,718 [training] [INFO] epoch 9 test loss:1.1498
2026-01-01 02:47:55,718 [training] [INFO] start training epochs 10
2026-01-01 02:47:56,755 [training] [INFO] training steps: 4600, Loss: 0.6280
2026-01-01 02:48:01,553 [training] [INFO] training steps: 4700, Loss: 0.9108
2026-01-01 02:48:06,362 [training] [INFO] training steps: 4800, Loss: 0.7871
2026-01-01 02:48:11,170 [training] [INFO] training steps: 4900, Loss: 0.5688
2026-01-01 02:48:15,975 [training] [INFO] training steps: 5000, Loss: 0.9701
2026-01-01 02:48:20,807 [training] [INFO] training steps: 5100, Loss: 0.8864
2026-01-01 02:48:20,841 [training] [INFO] epoch 10 train loss:0.7902536734062082
2026-01-01 02:48:22,176 [training] [INFO] epoch 10 test loss:0.7975
2026-01-01 02:48:22,176 [training] [INFO] start training epochs 11
2026-01-01 02:48:27,563 [training] [INFO] training steps: 5200, Loss: 1.0758
2026-01-01 02:48:32,386 [training] [INFO] training steps: 5300, Loss: 1.0109
2026-01-01 02:48:37,197 [training] [INFO] training steps: 5400, Loss: 0.6438
2026-01-01 02:48:42,009 [training] [INFO] training steps: 5500, Loss: 0.5694
2026-01-01 02:48:46,866 [training] [INFO] training steps: 5600, Loss: 0.5514
2026-01-01 02:48:47,382 [training] [INFO] epoch 11 train loss:0.7792835998184541
2026-01-01 02:48:48,719 [training] [INFO] epoch 11 test loss:0.7694
2026-01-01 02:48:48,719 [training] [INFO] start training epochs 12
2026-01-01 02:48:53,598 [training] [INFO] training steps: 5700, Loss: 0.5912
2026-01-01 02:48:58,442 [training] [INFO] training steps: 5800, Loss: 0.5839
2026-01-01 02:49:03,254 [training] [INFO] training steps: 5900, Loss: 0.6556
2026-01-01 02:49:08,125 [training] [INFO] training steps: 6000, Loss: 0.4947
2026-01-01 02:49:12,919 [training] [INFO] training steps: 6100, Loss: 1.3321
2026-01-01 02:49:13,913 [training] [INFO] epoch 12 train loss:0.7514687927914601
2026-01-01 02:49:15,241 [training] [INFO] epoch 12 test loss:0.7992
2026-01-01 02:49:15,241 [training] [INFO] start training epochs 13
2026-01-01 02:49:19,636 [training] [INFO] training steps: 6200, Loss: 0.8379
2026-01-01 02:49:24,445 [training] [INFO] training steps: 6300, Loss: 0.7733
2026-01-01 02:49:29,325 [training] [INFO] training steps: 6400, Loss: 1.0697
2026-01-01 02:49:34,189 [training] [INFO] training steps: 6500, Loss: 0.8820
2026-01-01 02:49:38,992 [training] [INFO] training steps: 6600, Loss: 0.6691
2026-01-01 02:49:40,474 [training] [INFO] epoch 13 train loss:0.760753206762613
2026-01-01 02:49:41,818 [training] [INFO] epoch 13 test loss:0.9075
2026-01-01 02:49:41,818 [training] [INFO] start training epochs 14
2026-01-01 02:49:45,737 [training] [INFO] training steps: 6700, Loss: 0.8376
2026-01-01 02:49:50,536 [training] [INFO] training steps: 6800, Loss: 0.5159
2026-01-01 02:49:55,406 [training] [INFO] training steps: 6900, Loss: 1.2287
2026-01-01 02:50:00,190 [training] [INFO] training steps: 7000, Loss: 0.6408
2026-01-01 02:50:04,975 [training] [INFO] training steps: 7100, Loss: 0.7397
2026-01-01 02:50:06,927 [training] [INFO] epoch 14 train loss:0.7591531892617543
2026-01-01 02:50:08,267 [training] [INFO] epoch 14 test loss:0.7052
2026-01-01 02:50:08,268 [training] [INFO] start training epochs 15
2026-01-01 02:50:11,693 [training] [INFO] training steps: 7200, Loss: 0.8385
2026-01-01 02:50:16,579 [training] [INFO] training steps: 7300, Loss: 0.5073
2026-01-01 02:50:21,439 [training] [INFO] training steps: 7400, Loss: 0.4157
2026-01-01 02:50:26,295 [training] [INFO] training steps: 7500, Loss: 0.5714
2026-01-01 02:50:31,145 [training] [INFO] training steps: 7600, Loss: 0.5378
2026-01-01 02:50:33,609 [training] [INFO] epoch 15 train loss:0.6715378657859914
2026-01-01 02:50:34,970 [training] [INFO] epoch 15 test loss:0.6170
2026-01-01 02:50:34,970 [training] [INFO] start training epochs 16
2026-01-01 02:50:37,907 [training] [INFO] training steps: 7700, Loss: 0.9311
2026-01-01 02:50:42,779 [training] [INFO] training steps: 7800, Loss: 1.9711
2026-01-01 02:50:47,556 [training] [INFO] training steps: 7900, Loss: 0.4887
2026-01-01 02:50:52,335 [training] [INFO] training steps: 8000, Loss: 0.6756
2026-01-01 02:50:57,111 [training] [INFO] training steps: 8100, Loss: 0.5654
2026-01-01 02:51:00,017 [training] [INFO] epoch 16 train loss:0.6795583819057427
2026-01-01 02:51:01,456 [training] [INFO] epoch 16 test loss:0.7952
2026-01-01 02:51:01,456 [training] [INFO] start training epochs 17
2026-01-01 02:51:03,993 [training] [INFO] training steps: 8200, Loss: 0.5016
2026-01-01 02:51:08,759 [training] [INFO] training steps: 8300, Loss: 0.6350
2026-01-01 02:51:13,537 [training] [INFO] training steps: 8400, Loss: 0.6248
2026-01-01 02:51:18,441 [training] [INFO] training steps: 8500, Loss: 0.6667
2026-01-01 02:51:23,228 [training] [INFO] training steps: 8600, Loss: 0.4169
2026-01-01 02:51:26,616 [training] [INFO] epoch 17 train loss:0.6935862405627382
2026-01-01 02:51:27,964 [training] [INFO] epoch 17 test loss:0.6727
2026-01-01 02:51:27,964 [training] [INFO] start training epochs 18
2026-01-01 02:51:30,003 [training] [INFO] training steps: 8700, Loss: 0.6988
2026-01-01 02:51:34,804 [training] [INFO] training steps: 8800, Loss: 0.5411
2026-01-01 02:51:39,605 [training] [INFO] training steps: 8900, Loss: 0.6569
2026-01-01 02:51:44,404 [training] [INFO] training steps: 9000, Loss: 0.6477
2026-01-01 02:51:49,216 [training] [INFO] training steps: 9100, Loss: 0.5614
2026-01-01 02:51:53,093 [training] [INFO] epoch 18 train loss:0.6629693359136581
2026-01-01 02:51:54,437 [training] [INFO] epoch 18 test loss:0.7350
2026-01-01 02:51:54,437 [training] [INFO] start training epochs 19
2026-01-01 02:51:55,981 [training] [INFO] training steps: 9200, Loss: 0.6208
2026-01-01 02:52:00,745 [training] [INFO] training steps: 9300, Loss: 0.3872
2026-01-01 02:52:05,509 [training] [INFO] training steps: 9400, Loss: 0.4570
2026-01-01 02:52:10,281 [training] [INFO] training steps: 9500, Loss: 0.7915
2026-01-01 02:52:15,045 [training] [INFO] training steps: 9600, Loss: 0.4598
2026-01-01 02:52:19,363 [training] [INFO] epoch 19 train loss:0.6288292714778114
2026-01-01 02:52:20,698 [training] [INFO] epoch 19 test loss:0.8735
2026-01-01 02:52:20,698 [training] [INFO] start training epochs 20
2026-01-01 02:52:21,713 [training] [INFO] training steps: 9700, Loss: 0.4554
2026-01-01 02:52:26,503 [training] [INFO] training steps: 9800, Loss: 0.5450
2026-01-01 02:52:31,289 [training] [INFO] training steps: 9900, Loss: 0.4880
2026-01-01 02:52:36,080 [training] [INFO] training steps: 10000, Loss: 0.8488
2026-01-01 02:52:40,885 [training] [INFO] training steps: 10100, Loss: 0.5697
2026-01-01 02:52:45,701 [training] [INFO] training steps: 10200, Loss: 0.9938
2026-01-01 02:52:45,724 [training] [INFO] epoch 20 train loss:0.6359093532258389
2026-01-01 02:52:47,062 [training] [INFO] epoch 20 test loss:0.5508
2026-01-01 02:52:47,063 [training] [INFO] start training epochs 21
2026-01-01 02:52:52,417 [training] [INFO] training steps: 10300, Loss: 0.4728
2026-01-01 02:52:57,200 [training] [INFO] training steps: 10400, Loss: 0.6981
2026-01-01 02:53:01,988 [training] [INFO] training steps: 10500, Loss: 0.4666
2026-01-01 02:53:06,779 [training] [INFO] training steps: 10600, Loss: 0.5278
2026-01-01 02:53:11,563 [training] [INFO] training steps: 10700, Loss: 0.6921
2026-01-01 02:53:12,071 [training] [INFO] epoch 21 train loss:0.6043464291329478
2026-01-01 02:53:13,439 [training] [INFO] epoch 21 test loss:0.7543
2026-01-01 02:53:13,439 [training] [INFO] start training epochs 22
2026-01-01 02:53:18,282 [training] [INFO] training steps: 10800, Loss: 0.6525
2026-01-01 02:53:23,075 [training] [INFO] training steps: 10900, Loss: 0.6343
2026-01-01 02:53:27,860 [training] [INFO] training steps: 11000, Loss: 0.7866
2026-01-01 02:53:32,647 [training] [INFO] training steps: 11100, Loss: 0.4818
2026-01-01 02:53:37,434 [training] [INFO] training steps: 11200, Loss: 0.6421
2026-01-01 02:53:38,424 [training] [INFO] epoch 22 train loss:0.6109067239597732
2026-01-01 02:53:39,750 [training] [INFO] epoch 22 test loss:0.5596
2026-01-01 02:53:39,751 [training] [INFO] start training epochs 23
2026-01-01 02:53:44,118 [training] [INFO] training steps: 11300, Loss: 0.3458
2026-01-01 02:53:48,886 [training] [INFO] training steps: 11400, Loss: 0.5124
2026-01-01 02:53:53,658 [training] [INFO] training steps: 11500, Loss: 0.3712
2026-01-01 02:53:58,434 [training] [INFO] training steps: 11600, Loss: 0.5747
2026-01-01 02:54:03,207 [training] [INFO] training steps: 11700, Loss: 0.5776
2026-01-01 02:54:04,666 [training] [INFO] epoch 23 train loss:0.5819279195631252
2026-01-01 02:54:06,002 [training] [INFO] epoch 23 test loss:0.5606
2026-01-01 02:54:06,002 [training] [INFO] start training epochs 24
2026-01-01 02:54:09,887 [training] [INFO] training steps: 11800, Loss: 0.5311
2026-01-01 02:54:14,668 [training] [INFO] training steps: 11900, Loss: 0.6294
2026-01-01 02:54:19,465 [training] [INFO] training steps: 12000, Loss: 0.5812
2026-01-01 02:54:24,256 [training] [INFO] training steps: 12100, Loss: 0.5992
2026-01-01 02:54:29,050 [training] [INFO] training steps: 12200, Loss: 0.4701
2026-01-01 02:54:31,000 [training] [INFO] epoch 24 train loss:0.5717267451917424
2026-01-01 02:54:32,342 [training] [INFO] epoch 24 test loss:0.8359
2026-01-01 02:54:32,342 [training] [INFO] start training epochs 25
2026-01-01 02:54:35,766 [training] [INFO] training steps: 12300, Loss: 0.5107
2026-01-01 02:54:40,560 [training] [INFO] training steps: 12400, Loss: 0.6607
2026-01-01 02:54:45,350 [training] [INFO] training steps: 12500, Loss: 0.5455
2026-01-01 02:54:50,138 [training] [INFO] training steps: 12600, Loss: 0.6024
2026-01-01 02:54:54,930 [training] [INFO] training steps: 12700, Loss: 0.4854
2026-01-01 02:54:57,351 [training] [INFO] epoch 25 train loss:0.5833471647080253
2026-01-01 02:54:58,676 [training] [INFO] epoch 25 test loss:0.8544
2026-01-01 02:54:58,677 [training] [INFO] start training epochs 26
2026-01-01 02:55:01,640 [training] [INFO] training steps: 12800, Loss: 0.5772
2026-01-01 02:55:06,407 [training] [INFO] training steps: 12900, Loss: 0.7590
2026-01-01 02:55:11,175 [training] [INFO] training steps: 13000, Loss: 0.3923
2026-01-01 02:55:15,951 [training] [INFO] training steps: 13100, Loss: 0.5344
2026-01-01 02:55:20,723 [training] [INFO] training steps: 13200, Loss: 0.3694
2026-01-01 02:55:23,614 [training] [INFO] epoch 26 train loss:0.5766445914319918
2026-01-01 02:55:24,960 [training] [INFO] epoch 26 test loss:0.5368
2026-01-01 02:55:24,961 [training] [INFO] start training epochs 27
2026-01-01 02:55:27,439 [training] [INFO] training steps: 13300, Loss: 0.6627
2026-01-01 02:55:32,222 [training] [INFO] training steps: 13400, Loss: 0.6761
2026-01-01 02:55:37,011 [training] [INFO] training steps: 13500, Loss: 0.4962
2026-01-01 02:55:41,791 [training] [INFO] training steps: 13600, Loss: 0.4279
2026-01-01 02:55:46,572 [training] [INFO] training steps: 13700, Loss: 0.3624
2026-01-01 02:55:49,950 [training] [INFO] epoch 27 train loss:0.5564481672703051
2026-01-01 02:55:51,294 [training] [INFO] epoch 27 test loss:0.5038
2026-01-01 02:55:51,295 [training] [INFO] start training epochs 28
2026-01-01 02:55:53,281 [training] [INFO] training steps: 13800, Loss: 0.4729
2026-01-01 02:55:57,986 [training] [INFO] training steps: 13900, Loss: 0.4932
2026-01-01 02:56:02,689 [training] [INFO] training steps: 14000, Loss: 0.5174
2026-01-01 02:56:07,392 [training] [INFO] training steps: 14100, Loss: 0.6183
2026-01-01 02:56:12,099 [training] [INFO] training steps: 14200, Loss: 0.6247
2026-01-01 02:56:15,896 [training] [INFO] epoch 28 train loss:0.5363067352304272
2026-01-01 02:56:17,193 [training] [INFO] epoch 28 test loss:0.4736
2026-01-01 02:56:17,193 [training] [INFO] start training epochs 29
2026-01-01 02:56:18,716 [training] [INFO] training steps: 14300, Loss: 0.4500
2026-01-01 02:56:23,446 [training] [INFO] training steps: 14400, Loss: 0.6490
2026-01-01 02:56:28,181 [training] [INFO] training steps: 14500, Loss: 0.6675
2026-01-01 02:56:32,916 [training] [INFO] training steps: 14600, Loss: 0.5583
2026-01-01 02:56:37,650 [training] [INFO] training steps: 14700, Loss: 0.4950
2026-01-01 02:56:41,944 [training] [INFO] epoch 29 train loss:0.5273371885804569
2026-01-01 02:56:43,258 [training] [INFO] epoch 29 test loss:0.5267
2026-01-01 02:56:43,258 [training] [INFO] start training epochs 30
2026-01-01 02:56:44,297 [training] [INFO] training steps: 14800, Loss: 0.3894
2026-01-01 02:56:49,025 [training] [INFO] training steps: 14900, Loss: 0.4962
2026-01-01 02:56:53,748 [training] [INFO] training steps: 15000, Loss: 0.4067
2026-01-01 02:56:58,471 [training] [INFO] training steps: 15100, Loss: 0.5870
2026-01-01 02:57:03,198 [training] [INFO] training steps: 15200, Loss: 0.3725
2026-01-01 02:57:07,932 [training] [INFO] training steps: 15300, Loss: 0.4839
2026-01-01 02:57:07,955 [training] [INFO] epoch 30 train loss:0.5383836161272199
2026-01-01 02:57:09,267 [training] [INFO] epoch 30 test loss:0.5796
2026-01-01 02:57:09,268 [training] [INFO] start training epochs 31
2026-01-01 02:57:14,561 [training] [INFO] training steps: 15400, Loss: 0.5003
2026-01-01 02:57:19,279 [training] [INFO] training steps: 15500, Loss: 0.6541
2026-01-01 02:57:23,998 [training] [INFO] training steps: 15600, Loss: 0.4468
2026-01-01 02:57:28,715 [training] [INFO] training steps: 15700, Loss: 0.5556
2026-01-01 02:57:33,432 [training] [INFO] training steps: 15800, Loss: 0.4300
2026-01-01 02:57:33,934 [training] [INFO] epoch 31 train loss:0.5189529089366689
2026-01-01 02:57:35,286 [training] [INFO] epoch 31 test loss:0.5562
2026-01-01 02:57:35,286 [training] [INFO] start training epochs 32
2026-01-01 02:57:40,055 [training] [INFO] training steps: 15900, Loss: 0.4479
2026-01-01 02:57:44,752 [training] [INFO] training steps: 16000, Loss: 0.6988
2026-01-01 02:57:49,446 [training] [INFO] training steps: 16100, Loss: 0.4763
2026-01-01 02:57:54,143 [training] [INFO] training steps: 16200, Loss: 0.3931
2026-01-01 02:57:58,844 [training] [INFO] training steps: 16300, Loss: 0.3651
2026-01-01 02:57:59,807 [training] [INFO] epoch 32 train loss:0.5063974675010232
2026-01-01 02:58:01,118 [training] [INFO] epoch 32 test loss:0.5433
2026-01-01 02:58:01,118 [training] [INFO] start training epochs 33
2026-01-01 02:58:05,461 [training] [INFO] training steps: 16400, Loss: 0.5279
2026-01-01 02:58:10,173 [training] [INFO] training steps: 16500, Loss: 0.5409
2026-01-01 02:58:14,886 [training] [INFO] training steps: 16600, Loss: 0.4566
2026-01-01 02:58:19,599 [training] [INFO] training steps: 16700, Loss: 0.5523
2026-01-01 02:58:24,312 [training] [INFO] training steps: 16800, Loss: 0.4156
2026-01-01 02:58:25,759 [training] [INFO] epoch 33 train loss:0.5207213477176779
2026-01-01 02:58:27,056 [training] [INFO] epoch 33 test loss:0.4782
2026-01-01 02:58:27,057 [training] [INFO] start training epochs 34
2026-01-01 02:58:30,926 [training] [INFO] training steps: 16900, Loss: 0.4650
2026-01-01 02:58:35,646 [training] [INFO] training steps: 17000, Loss: 0.4316
2026-01-01 02:58:40,366 [training] [INFO] training steps: 17100, Loss: 0.4061
2026-01-01 02:58:45,088 [training] [INFO] training steps: 17200, Loss: 0.3970
2026-01-01 02:58:49,812 [training] [INFO] training steps: 17300, Loss: 0.3940
2026-01-01 02:58:51,732 [training] [INFO] epoch 34 train loss:0.505008129103511
2026-01-01 02:58:53,042 [training] [INFO] epoch 34 test loss:0.4500
2026-01-01 02:58:53,043 [training] [INFO] start training epochs 35
2026-01-01 02:58:56,360 [training] [INFO] training steps: 17400, Loss: 0.5076
2026-01-01 02:59:01,054 [training] [INFO] training steps: 17500, Loss: 0.6951
2026-01-01 02:59:05,765 [training] [INFO] training steps: 17600, Loss: 0.6189
2026-01-01 02:59:10,481 [training] [INFO] training steps: 17700, Loss: 0.5005
2026-01-01 02:59:15,194 [training] [INFO] training steps: 17800, Loss: 0.6038
2026-01-01 02:59:17,582 [training] [INFO] epoch 35 train loss:0.4971847067860996
2026-01-01 02:59:18,903 [training] [INFO] epoch 35 test loss:0.5418
2026-01-01 02:59:18,904 [training] [INFO] start training epochs 36
2026-01-01 02:59:21,785 [training] [INFO] training steps: 17900, Loss: 0.3391
2026-01-01 02:59:26,485 [training] [INFO] training steps: 18000, Loss: 0.4880
2026-01-01 02:59:31,183 [training] [INFO] training steps: 18100, Loss: 0.4741
2026-01-01 02:59:35,883 [training] [INFO] training steps: 18200, Loss: 0.5349
2026-01-01 02:59:40,585 [training] [INFO] training steps: 18300, Loss: 0.3368
2026-01-01 02:59:43,444 [training] [INFO] epoch 36 train loss:0.4831730359909581
2026-01-01 02:59:44,740 [training] [INFO] epoch 36 test loss:0.5000
2026-01-01 02:59:44,740 [training] [INFO] start training epochs 37
2026-01-01 02:59:47,156 [training] [INFO] training steps: 18400, Loss: 0.3580
2026-01-01 02:59:51,854 [training] [INFO] training steps: 18500, Loss: 0.6443
2026-01-01 02:59:56,556 [training] [INFO] training steps: 18600, Loss: 0.4022
2026-01-01 03:00:01,260 [training] [INFO] training steps: 18700, Loss: 0.4347
2026-01-01 03:00:05,961 [training] [INFO] training steps: 18800, Loss: 0.6469
2026-01-01 03:00:09,288 [training] [INFO] epoch 37 train loss:0.4806478371807173
2026-01-01 03:00:10,602 [training] [INFO] epoch 37 test loss:0.4919
2026-01-01 03:00:10,602 [training] [INFO] start training epochs 38
2026-01-01 03:00:12,557 [training] [INFO] training steps: 18900, Loss: 0.5126
2026-01-01 03:00:17,291 [training] [INFO] training steps: 19000, Loss: 0.4933
2026-01-01 03:00:22,023 [training] [INFO] training steps: 19100, Loss: 0.4478
2026-01-01 03:00:26,757 [training] [INFO] training steps: 19200, Loss: 0.4195
2026-01-01 03:00:31,493 [training] [INFO] training steps: 19300, Loss: 0.4480
2026-01-01 03:00:35,305 [training] [INFO] epoch 38 train loss:0.4813875089673435
2026-01-01 03:00:36,596 [training] [INFO] epoch 38 test loss:0.4572
2026-01-01 03:00:36,596 [training] [INFO] start training epochs 39
2026-01-01 03:00:38,119 [training] [INFO] training steps: 19400, Loss: 0.4446
2026-01-01 03:00:42,820 [training] [INFO] training steps: 19500, Loss: 0.6074
2026-01-01 03:00:47,521 [training] [INFO] training steps: 19600, Loss: 0.6587
2026-01-01 03:00:52,222 [training] [INFO] training steps: 19700, Loss: 0.4385
2026-01-01 03:00:56,921 [training] [INFO] training steps: 19800, Loss: 0.3499
2026-01-01 03:01:01,178 [training] [INFO] epoch 39 train loss:0.46741566944356056
2026-01-01 03:01:02,494 [training] [INFO] epoch 39 test loss:0.6559
2026-01-01 03:01:02,494 [training] [INFO] start training epochs 40
2026-01-01 03:01:03,509 [training] [INFO] training steps: 19900, Loss: 0.4762
2026-01-01 03:01:08,209 [training] [INFO] training steps: 20000, Loss: 0.6499
2026-01-01 03:01:12,907 [training] [INFO] training steps: 20100, Loss: 0.4354
2026-01-01 03:01:17,607 [training] [INFO] training steps: 20200, Loss: 0.5754
2026-01-01 03:01:22,308 [training] [INFO] training steps: 20300, Loss: 0.3977
2026-01-01 03:01:27,016 [training] [INFO] training steps: 20400, Loss: 0.3630
2026-01-01 03:01:27,040 [training] [INFO] epoch 40 train loss:0.46684428476819806
2026-01-01 03:01:28,354 [training] [INFO] epoch 40 test loss:0.6123
2026-01-01 03:01:28,355 [training] [INFO] start training epochs 41
2026-01-01 03:01:33,616 [training] [INFO] training steps: 20500, Loss: 0.6321
2026-01-01 03:01:38,330 [training] [INFO] training steps: 20600, Loss: 0.4533
2026-01-01 03:01:43,048 [training] [INFO] training steps: 20700, Loss: 0.3664
2026-01-01 03:01:47,765 [training] [INFO] training steps: 20800, Loss: 0.3650
2026-01-01 03:01:52,485 [training] [INFO] training steps: 20900, Loss: 0.5204
2026-01-01 03:01:52,984 [training] [INFO] epoch 41 train loss:0.451772843505822
2026-01-01 03:01:54,285 [training] [INFO] epoch 41 test loss:0.4111
2026-01-01 03:01:54,285 [training] [INFO] start training epochs 42
2026-01-01 03:01:59,092 [training] [INFO] training steps: 21000, Loss: 0.4938
2026-01-01 03:02:03,833 [training] [INFO] training steps: 21100, Loss: 0.3684
2026-01-01 03:02:08,573 [training] [INFO] training steps: 21200, Loss: 0.3821
2026-01-01 03:02:13,318 [training] [INFO] training steps: 21300, Loss: 0.4829
2026-01-01 03:02:18,060 [training] [INFO] training steps: 21400, Loss: 0.5531
2026-01-01 03:02:19,035 [training] [INFO] epoch 42 train loss:0.44082582417656396
2026-01-01 03:02:20,365 [training] [INFO] epoch 42 test loss:0.4140
2026-01-01 03:02:20,365 [training] [INFO] start training epochs 43
2026-01-01 03:02:24,714 [training] [INFO] training steps: 21500, Loss: 0.3433
2026-01-01 03:02:29,432 [training] [INFO] training steps: 21600, Loss: 0.4291
2026-01-01 03:02:34,147 [training] [INFO] training steps: 21700, Loss: 0.6114
2026-01-01 03:02:38,861 [training] [INFO] training steps: 21800, Loss: 0.3798
2026-01-01 03:02:43,575 [training] [INFO] training steps: 21900, Loss: 0.4379
2026-01-01 03:02:45,017 [training] [INFO] epoch 43 train loss:0.4414076559683856
2026-01-01 03:02:46,325 [training] [INFO] epoch 43 test loss:0.4943
2026-01-01 03:02:46,326 [training] [INFO] start training epochs 44
2026-01-01 03:02:50,192 [training] [INFO] training steps: 22000, Loss: 0.4471
2026-01-01 03:02:54,913 [training] [INFO] training steps: 22100, Loss: 0.4064
2026-01-01 03:02:59,635 [training] [INFO] training steps: 22200, Loss: 0.3515
2026-01-01 03:03:04,356 [training] [INFO] training steps: 22300, Loss: 0.3358
2026-01-01 03:03:09,079 [training] [INFO] training steps: 22400, Loss: 0.5004
2026-01-01 03:03:10,994 [training] [INFO] epoch 44 train loss:0.4339402223918952
2026-01-01 03:03:12,281 [training] [INFO] epoch 44 test loss:0.4423
2026-01-01 03:03:12,281 [training] [INFO] start training epochs 45
2026-01-01 03:03:15,663 [training] [INFO] training steps: 22500, Loss: 0.7210
2026-01-01 03:03:20,384 [training] [INFO] training steps: 22600, Loss: 0.3738
2026-01-01 03:03:25,109 [training] [INFO] training steps: 22700, Loss: 0.5793
2026-01-01 03:03:29,831 [training] [INFO] training steps: 22800, Loss: 0.4615
2026-01-01 03:03:34,553 [training] [INFO] training steps: 22900, Loss: 0.3943
2026-01-01 03:03:36,937 [training] [INFO] epoch 45 train loss:0.4683633489351647
2026-01-01 03:03:38,207 [training] [INFO] epoch 45 test loss:0.4464
2026-01-01 03:03:38,207 [training] [INFO] start training epochs 46
2026-01-01 03:03:41,134 [training] [INFO] training steps: 23000, Loss: 0.3886
2026-01-01 03:03:45,856 [training] [INFO] training steps: 23100, Loss: 0.3495
2026-01-01 03:03:50,576 [training] [INFO] training steps: 23200, Loss: 0.2861
2026-01-01 03:03:55,297 [training] [INFO] training steps: 23300, Loss: 0.3670
2026-01-01 03:04:00,020 [training] [INFO] training steps: 23400, Loss: 0.4622
2026-01-01 03:04:02,883 [training] [INFO] epoch 46 train loss:0.436153462879798
2026-01-01 03:04:04,206 [training] [INFO] epoch 46 test loss:0.4568
2026-01-01 03:04:04,206 [training] [INFO] start training epochs 47
2026-01-01 03:04:06,640 [training] [INFO] training steps: 23500, Loss: 0.6569
2026-01-01 03:04:11,341 [training] [INFO] training steps: 23600, Loss: 0.3270
2026-01-01 03:04:16,043 [training] [INFO] training steps: 23700, Loss: 0.4257
2026-01-01 03:04:20,747 [training] [INFO] training steps: 23800, Loss: 0.5417
2026-01-01 03:04:25,449 [training] [INFO] training steps: 23900, Loss: 0.3783
2026-01-01 03:04:28,781 [training] [INFO] epoch 47 train loss:0.4325599322716395
2026-01-01 03:04:30,096 [training] [INFO] epoch 47 test loss:0.4353
2026-01-01 03:04:30,096 [training] [INFO] start training epochs 48
2026-01-01 03:04:32,041 [training] [INFO] training steps: 24000, Loss: 0.4070
2026-01-01 03:04:36,762 [training] [INFO] training steps: 24100, Loss: 0.4748
2026-01-01 03:04:41,482 [training] [INFO] training steps: 24200, Loss: 0.3096
2026-01-01 03:04:46,204 [training] [INFO] training steps: 24300, Loss: 0.3144
2026-01-01 03:04:50,933 [training] [INFO] training steps: 24400, Loss: 0.4568
2026-01-01 03:04:54,744 [training] [INFO] epoch 48 train loss:0.4244688680943321
2026-01-01 03:04:56,051 [training] [INFO] epoch 48 test loss:0.5208
2026-01-01 03:04:56,051 [training] [INFO] start training epochs 49
2026-01-01 03:04:57,516 [training] [INFO] training steps: 24500, Loss: 0.4118
2026-01-01 03:05:02,213 [training] [INFO] training steps: 24600, Loss: 0.3519
2026-01-01 03:05:06,915 [training] [INFO] training steps: 24700, Loss: 0.4679
2026-01-01 03:05:11,617 [training] [INFO] training steps: 24800, Loss: 0.3514
2026-01-01 03:05:16,315 [training] [INFO] training steps: 24900, Loss: 0.2855
2026-01-01 03:05:20,571 [training] [INFO] epoch 49 train loss:0.4216687224659265
2026-01-01 03:05:21,919 [training] [INFO] epoch 49 test loss:0.4220
2026-01-01 03:05:21,920 [training] [INFO] start training epochs 50
2026-01-01 03:05:22,971 [training] [INFO] training steps: 25000, Loss: 0.4263
2026-01-01 03:05:27,720 [training] [INFO] training steps: 25100, Loss: 0.3785
2026-01-01 03:05:32,463 [training] [INFO] training steps: 25200, Loss: 0.5346
2026-01-01 03:05:37,205 [training] [INFO] training steps: 25300, Loss: 0.3346
2026-01-01 03:05:41,949 [training] [INFO] training steps: 25400, Loss: 0.4952
2026-01-01 03:05:46,697 [training] [INFO] training steps: 25500, Loss: 0.5708
2026-01-01 03:05:46,720 [training] [INFO] epoch 50 train loss:0.42351690524933383
2026-01-01 03:05:48,034 [training] [INFO] epoch 50 test loss:0.4098
2026-01-01 03:05:48,035 [training] [INFO] start training epochs 51
2026-01-01 03:05:53,307 [training] [INFO] training steps: 25600, Loss: 0.4182
2026-01-01 03:05:58,015 [training] [INFO] training steps: 25700, Loss: 0.5477
2026-01-01 03:06:02,728 [training] [INFO] training steps: 25800, Loss: 0.4205
2026-01-01 03:06:07,441 [training] [INFO] training steps: 25900, Loss: 0.3969
2026-01-01 03:06:12,151 [training] [INFO] training steps: 26000, Loss: 0.3325
2026-01-01 03:06:12,657 [training] [INFO] epoch 51 train loss:0.4225329427742491
2026-01-01 03:06:13,978 [training] [INFO] epoch 51 test loss:0.4708
2026-01-01 03:06:13,979 [training] [INFO] start training epochs 52
2026-01-01 03:06:18,770 [training] [INFO] training steps: 26100, Loss: 0.3883
2026-01-01 03:06:23,485 [training] [INFO] training steps: 26200, Loss: 0.4998
2026-01-01 03:06:28,198 [training] [INFO] training steps: 26300, Loss: 0.3969
2026-01-01 03:06:32,914 [training] [INFO] training steps: 26400, Loss: 0.4990
2026-01-01 03:06:37,628 [training] [INFO] training steps: 26500, Loss: 0.4098
2026-01-01 03:06:38,602 [training] [INFO] epoch 52 train loss:0.4155044750840056
2026-01-01 03:06:39,917 [training] [INFO] epoch 52 test loss:0.4344
2026-01-01 03:06:39,917 [training] [INFO] start training epochs 53
2026-01-01 03:06:44,263 [training] [INFO] training steps: 26600, Loss: 0.3002
2026-01-01 03:06:48,992 [training] [INFO] training steps: 26700, Loss: 0.4822
2026-01-01 03:06:53,718 [training] [INFO] training steps: 26800, Loss: 0.4140
2026-01-01 03:06:58,445 [training] [INFO] training steps: 26900, Loss: 0.5399
2026-01-01 03:07:03,173 [training] [INFO] training steps: 27000, Loss: 0.4106
2026-01-01 03:07:04,614 [training] [INFO] epoch 53 train loss:0.4131577747125252
2026-01-01 03:07:05,933 [training] [INFO] epoch 53 test loss:0.4006
2026-01-01 03:07:05,933 [training] [INFO] start training epochs 54
2026-01-01 03:07:09,799 [training] [INFO] training steps: 27100, Loss: 0.4790
2026-01-01 03:07:14,532 [training] [INFO] training steps: 27200, Loss: 0.4634
2026-01-01 03:07:19,265 [training] [INFO] training steps: 27300, Loss: 0.3312
2026-01-01 03:07:24,001 [training] [INFO] training steps: 27400, Loss: 0.3162
2026-01-01 03:07:28,741 [training] [INFO] training steps: 27500, Loss: 0.2420
2026-01-01 03:07:30,667 [training] [INFO] epoch 54 train loss:0.41218358395146387
2026-01-01 03:07:31,982 [training] [INFO] epoch 54 test loss:0.4710
2026-01-01 03:07:31,982 [training] [INFO] start training epochs 55
2026-01-01 03:07:35,353 [training] [INFO] training steps: 27600, Loss: 0.3699
2026-01-01 03:07:40,095 [training] [INFO] training steps: 27700, Loss: 0.3438
2026-01-01 03:07:44,838 [training] [INFO] training steps: 27800, Loss: 0.3888
2026-01-01 03:07:49,543 [training] [INFO] training steps: 27900, Loss: 0.3641
2026-01-01 03:07:54,258 [training] [INFO] training steps: 28000, Loss: 0.4049
2026-01-01 03:07:56,644 [training] [INFO] epoch 55 train loss:0.4248219873975305
2026-01-01 03:07:57,961 [training] [INFO] epoch 55 test loss:0.4049
2026-01-01 03:07:57,961 [training] [INFO] start training epochs 56
2026-01-01 03:08:00,907 [training] [INFO] training steps: 28100, Loss: 0.3239
2026-01-01 03:08:05,626 [training] [INFO] training steps: 28200, Loss: 0.4908
2026-01-01 03:08:10,334 [training] [INFO] training steps: 28300, Loss: 0.3208
2026-01-01 03:08:15,053 [training] [INFO] training steps: 28400, Loss: 0.5050
2026-01-01 03:08:19,769 [training] [INFO] training steps: 28500, Loss: 0.4958
2026-01-01 03:08:22,627 [training] [INFO] epoch 56 train loss:0.41641665773064485
2026-01-01 03:08:23,927 [training] [INFO] epoch 56 test loss:0.4444
2026-01-01 03:08:23,928 [training] [INFO] start training epochs 57
2026-01-01 03:08:26,396 [training] [INFO] training steps: 28600, Loss: 0.4039
2026-01-01 03:08:31,129 [training] [INFO] training steps: 28700, Loss: 0.4719
2026-01-01 03:08:35,862 [training] [INFO] training steps: 28800, Loss: 0.2877
2026-01-01 03:08:40,594 [training] [INFO] training steps: 28900, Loss: 0.3623
2026-01-01 03:08:45,322 [training] [INFO] training steps: 29000, Loss: 0.6124
2026-01-01 03:08:48,656 [training] [INFO] epoch 57 train loss:0.4002732018045351
2026-01-01 03:08:49,965 [training] [INFO] epoch 57 test loss:0.3840
2026-01-01 03:08:49,966 [training] [INFO] start training epochs 58
2026-01-01 03:08:51,962 [training] [INFO] training steps: 29100, Loss: 0.4417
2026-01-01 03:08:56,712 [training] [INFO] training steps: 29200, Loss: 0.5933
2026-01-01 03:09:01,461 [training] [INFO] training steps: 29300, Loss: 0.3024
2026-01-01 03:09:06,208 [training] [INFO] training steps: 29400, Loss: 0.3627
2026-01-01 03:09:10,956 [training] [INFO] training steps: 29500, Loss: 0.3261
2026-01-01 03:09:14,779 [training] [INFO] epoch 58 train loss:0.3891742387238671
2026-01-01 03:09:16,087 [training] [INFO] epoch 58 test loss:0.3856
2026-01-01 03:09:16,088 [training] [INFO] start training epochs 59
2026-01-01 03:09:17,580 [training] [INFO] training steps: 29600, Loss: 0.4042
2026-01-01 03:09:22,282 [training] [INFO] training steps: 29700, Loss: 0.4090
2026-01-01 03:09:26,990 [training] [INFO] training steps: 29800, Loss: 0.3867
2026-01-01 03:09:31,732 [training] [INFO] training steps: 29900, Loss: 0.3153
2026-01-01 03:09:36,478 [training] [INFO] training steps: 30000, Loss: 0.4694
2026-01-01 03:09:40,780 [training] [INFO] epoch 59 train loss:0.4093782089796721
2026-01-01 03:09:42,079 [training] [INFO] epoch 59 test loss:0.4508
2026-01-01 03:09:42,079 [training] [INFO] start training epochs 60
2026-01-01 03:09:43,091 [training] [INFO] training steps: 30100, Loss: 0.4474
2026-01-01 03:09:47,812 [training] [INFO] training steps: 30200, Loss: 0.5694
2026-01-01 03:09:52,533 [training] [INFO] training steps: 30300, Loss: 0.3455
2026-01-01 03:09:57,254 [training] [INFO] training steps: 30400, Loss: 0.4283
2026-01-01 03:10:01,977 [training] [INFO] training steps: 30500, Loss: 0.3033
2026-01-01 03:10:06,709 [training] [INFO] training steps: 30600, Loss: 0.5823
2026-01-01 03:10:06,731 [training] [INFO] epoch 60 train loss:0.40460039298324024
2026-01-01 03:10:08,051 [training] [INFO] epoch 60 test loss:0.4734
2026-01-01 03:10:08,052 [training] [INFO] start training epochs 61
2026-01-01 03:10:13,349 [training] [INFO] training steps: 30700, Loss: 0.4384
2026-01-01 03:10:18,061 [training] [INFO] training steps: 30800, Loss: 0.3541
2026-01-01 03:10:22,770 [training] [INFO] training steps: 30900, Loss: 0.3371
2026-01-01 03:10:27,479 [training] [INFO] training steps: 31000, Loss: 0.3368
2026-01-01 03:10:32,188 [training] [INFO] training steps: 31100, Loss: 0.3357
2026-01-01 03:10:32,690 [training] [INFO] epoch 61 train loss:0.38804250736446944
2026-01-01 03:10:34,005 [training] [INFO] epoch 61 test loss:0.3849
2026-01-01 03:10:34,006 [training] [INFO] start training epochs 62
2026-01-01 03:10:38,798 [training] [INFO] training steps: 31200, Loss: 0.4227
2026-01-01 03:10:43,506 [training] [INFO] training steps: 31300, Loss: 0.4892
2026-01-01 03:10:48,223 [training] [INFO] training steps: 31400, Loss: 0.3666
2026-01-01 03:10:52,946 [training] [INFO] training steps: 31500, Loss: 0.3366
2026-01-01 03:10:57,666 [training] [INFO] training steps: 31600, Loss: 0.3467
2026-01-01 03:10:58,641 [training] [INFO] epoch 62 train loss:0.38016937813338114
2026-01-01 03:10:59,950 [training] [INFO] epoch 62 test loss:0.3839
2026-01-01 03:10:59,950 [training] [INFO] start training epochs 63
2026-01-01 03:11:04,315 [training] [INFO] training steps: 31700, Loss: 0.3793
2026-01-01 03:11:09,062 [training] [INFO] training steps: 31800, Loss: 0.3686
2026-01-01 03:11:13,811 [training] [INFO] training steps: 31900, Loss: 0.3508
2026-01-01 03:11:18,558 [training] [INFO] training steps: 32000, Loss: 0.5125
2026-01-01 03:11:23,304 [training] [INFO] training steps: 32100, Loss: 0.4802
2026-01-01 03:11:24,755 [training] [INFO] epoch 63 train loss:0.3946282892250547
2026-01-01 03:11:26,065 [training] [INFO] epoch 63 test loss:0.4036
2026-01-01 03:11:26,065 [training] [INFO] start training epochs 64
2026-01-01 03:11:29,957 [training] [INFO] training steps: 32200, Loss: 0.4166
2026-01-01 03:11:34,693 [training] [INFO] training steps: 32300, Loss: 0.3640
2026-01-01 03:11:39,427 [training] [INFO] training steps: 32400, Loss: 0.4223
2026-01-01 03:11:44,166 [training] [INFO] training steps: 32500, Loss: 0.3579
2026-01-01 03:11:48,904 [training] [INFO] training steps: 32600, Loss: 0.3505
2026-01-01 03:11:50,823 [training] [INFO] epoch 64 train loss:0.37723500439349344
2026-01-01 03:11:52,119 [training] [INFO] epoch 64 test loss:0.3678
2026-01-01 03:11:52,119 [training] [INFO] start training epochs 65
2026-01-01 03:11:55,523 [training] [INFO] training steps: 32700, Loss: 0.3177
2026-01-01 03:12:00,242 [training] [INFO] training steps: 32800, Loss: 0.3879
2026-01-01 03:12:04,960 [training] [INFO] training steps: 32900, Loss: 0.3888
2026-01-01 03:12:09,677 [training] [INFO] training steps: 33000, Loss: 0.4485
2026-01-01 03:12:14,394 [training] [INFO] training steps: 33100, Loss: 0.3078
2026-01-01 03:12:16,785 [training] [INFO] epoch 65 train loss:0.36800722666815217
2026-01-01 03:12:18,114 [training] [INFO] epoch 65 test loss:0.3733
2026-01-01 03:12:18,115 [training] [INFO] start training epochs 66
2026-01-01 03:12:21,028 [training] [INFO] training steps: 33200, Loss: 0.2896
2026-01-01 03:12:25,757 [training] [INFO] training steps: 33300, Loss: 0.3731
2026-01-01 03:12:30,487 [training] [INFO] training steps: 33400, Loss: 0.4421
2026-01-01 03:12:35,219 [training] [INFO] training steps: 33500, Loss: 0.2600
2026-01-01 03:12:39,952 [training] [INFO] training steps: 33600, Loss: 0.3149
2026-01-01 03:12:42,811 [training] [INFO] epoch 66 train loss:0.3705488614007538
2026-01-01 03:12:44,130 [training] [INFO] epoch 66 test loss:0.3929
2026-01-01 03:12:44,130 [training] [INFO] start training epochs 67
2026-01-01 03:12:46,543 [training] [INFO] training steps: 33700, Loss: 0.3423
2026-01-01 03:12:51,266 [training] [INFO] training steps: 33800, Loss: 0.3005
2026-01-01 03:12:55,991 [training] [INFO] training steps: 33900, Loss: 0.3107
2026-01-01 03:13:00,712 [training] [INFO] training steps: 34000, Loss: 0.3621
2026-01-01 03:13:05,430 [training] [INFO] training steps: 34100, Loss: 0.4147
2026-01-01 03:13:08,765 [training] [INFO] epoch 67 train loss:0.374399645568109
2026-01-01 03:13:10,068 [training] [INFO] epoch 67 test loss:0.3682
2026-01-01 03:13:10,069 [training] [INFO] start training epochs 68
2026-01-01 03:13:12,028 [training] [INFO] training steps: 34200, Loss: 0.3617
2026-01-01 03:13:16,741 [training] [INFO] training steps: 34300, Loss: 0.5299
2026-01-01 03:13:21,452 [training] [INFO] training steps: 34400, Loss: 0.2938
2026-01-01 03:13:26,162 [training] [INFO] training steps: 34500, Loss: 0.3616
2026-01-01 03:13:30,875 [training] [INFO] training steps: 34600, Loss: 0.5156
2026-01-01 03:13:34,672 [training] [INFO] epoch 68 train loss:0.37854501079110536
2026-01-01 03:13:35,993 [training] [INFO] epoch 68 test loss:0.4895
2026-01-01 03:13:35,993 [training] [INFO] start training epochs 69
2026-01-01 03:13:37,526 [training] [INFO] training steps: 34700, Loss: 0.3279
2026-01-01 03:13:42,231 [training] [INFO] training steps: 34800, Loss: 0.3813
2026-01-01 03:13:46,934 [training] [INFO] training steps: 34900, Loss: 0.3786
2026-01-01 03:13:51,638 [training] [INFO] training steps: 35000, Loss: 0.3537
2026-01-01 03:13:56,339 [training] [INFO] training steps: 35100, Loss: 0.3387
2026-01-01 03:14:00,600 [training] [INFO] epoch 69 train loss:0.3654868029204069
2026-01-01 03:14:01,915 [training] [INFO] epoch 69 test loss:0.3766
2026-01-01 03:14:01,915 [training] [INFO] start training epochs 70
2026-01-01 03:14:02,917 [training] [INFO] training steps: 35200, Loss: 0.2971
2026-01-01 03:14:07,640 [training] [INFO] training steps: 35300, Loss: 0.4075
2026-01-01 03:14:12,362 [training] [INFO] training steps: 35400, Loss: 0.5391
2026-01-01 03:14:17,090 [training] [INFO] training steps: 35500, Loss: 0.3845
2026-01-01 03:14:21,815 [training] [INFO] training steps: 35600, Loss: 0.3447
2026-01-01 03:14:26,596 [training] [INFO] training steps: 35700, Loss: 0.3811
2026-01-01 03:14:26,625 [training] [INFO] epoch 70 train loss:0.3709303309227906
2026-01-01 03:14:27,936 [training] [INFO] epoch 70 test loss:0.3437
2026-01-01 03:14:27,937 [training] [INFO] start training epochs 71
2026-01-01 03:14:33,191 [training] [INFO] training steps: 35800, Loss: 0.2755
2026-01-01 03:14:37,906 [training] [INFO] training steps: 35900, Loss: 0.3283
2026-01-01 03:14:42,619 [training] [INFO] training steps: 36000, Loss: 0.2812
2026-01-01 03:14:47,386 [training] [INFO] training steps: 36100, Loss: 0.4207
2026-01-01 03:14:52,086 [training] [INFO] training steps: 36200, Loss: 0.2791
2026-01-01 03:14:52,595 [training] [INFO] epoch 71 train loss:0.36949332432419646
2026-01-01 03:14:53,911 [training] [INFO] epoch 71 test loss:0.3320
2026-01-01 03:14:53,911 [training] [INFO] start training epochs 72
2026-01-01 03:14:58,703 [training] [INFO] training steps: 36300, Loss: 0.3610
2026-01-01 03:15:03,436 [training] [INFO] training steps: 36400, Loss: 0.3897
2026-01-01 03:15:08,163 [training] [INFO] training steps: 36500, Loss: 0.3691
2026-01-01 03:15:12,947 [training] [INFO] training steps: 36600, Loss: 0.3915
2026-01-01 03:15:17,670 [training] [INFO] training steps: 36700, Loss: 0.3720
2026-01-01 03:15:18,656 [training] [INFO] epoch 72 train loss:0.36131453052455303
2026-01-01 03:15:19,944 [training] [INFO] epoch 72 test loss:0.3678
2026-01-01 03:15:19,944 [training] [INFO] start training epochs 73
2026-01-01 03:15:24,241 [training] [INFO] training steps: 36800, Loss: 0.2583
2026-01-01 03:15:28,954 [training] [INFO] training steps: 36900, Loss: 0.3533
2026-01-01 03:15:33,725 [training] [INFO] training steps: 37000, Loss: 0.4161
2026-01-01 03:15:38,422 [training] [INFO] training steps: 37100, Loss: 0.4946
2026-01-01 03:15:43,121 [training] [INFO] training steps: 37200, Loss: 0.4074
2026-01-01 03:15:44,565 [training] [INFO] epoch 73 train loss:0.3567540471460305
2026-01-01 03:15:45,883 [training] [INFO] epoch 73 test loss:0.4280
2026-01-01 03:15:45,883 [training] [INFO] start training epochs 74
2026-01-01 03:15:49,747 [training] [INFO] training steps: 37300, Loss: 0.3201
2026-01-01 03:15:54,470 [training] [INFO] training steps: 37400, Loss: 0.3762
2026-01-01 03:15:59,248 [training] [INFO] training steps: 37500, Loss: 0.3749
2026-01-01 03:16:03,958 [training] [INFO] training steps: 37600, Loss: 0.3470
2026-01-01 03:16:08,670 [training] [INFO] training steps: 37700, Loss: 0.3042
2026-01-01 03:16:10,587 [training] [INFO] epoch 74 train loss:0.35561005455606126
2026-01-01 03:16:11,881 [training] [INFO] epoch 74 test loss:0.3984
2026-01-01 03:16:11,881 [training] [INFO] start training epochs 75
2026-01-01 03:16:15,261 [training] [INFO] training steps: 37800, Loss: 0.3680
2026-01-01 03:16:20,026 [training] [INFO] training steps: 37900, Loss: 0.4011
2026-01-01 03:16:24,718 [training] [INFO] training steps: 38000, Loss: 0.2922
2026-01-01 03:16:29,412 [training] [INFO] training steps: 38100, Loss: 0.2737
2026-01-01 03:16:34,106 [training] [INFO] training steps: 38200, Loss: 0.3798
2026-01-01 03:16:36,491 [training] [INFO] epoch 75 train loss:0.3720824484731637
2026-01-01 03:16:37,796 [training] [INFO] epoch 75 test loss:0.3908
2026-01-01 03:16:37,797 [training] [INFO] start training epochs 76
2026-01-01 03:16:40,709 [training] [INFO] training steps: 38300, Loss: 0.3650
2026-01-01 03:16:45,504 [training] [INFO] training steps: 38400, Loss: 0.2513
2026-01-01 03:16:50,233 [training] [INFO] training steps: 38500, Loss: 0.3773
2026-01-01 03:16:54,965 [training] [INFO] training steps: 38600, Loss: 0.3796
2026-01-01 03:16:59,699 [training] [INFO] training steps: 38700, Loss: 0.2799
2026-01-01 03:17:02,680 [training] [INFO] epoch 76 train loss:0.3511948225544948
2026-01-01 03:17:03,997 [training] [INFO] epoch 76 test loss:0.3454
2026-01-01 03:17:03,998 [training] [INFO] start training epochs 77
2026-01-01 03:17:06,454 [training] [INFO] training steps: 38800, Loss: 0.3826
2026-01-01 03:17:11,179 [training] [INFO] training steps: 38900, Loss: 0.2986
2026-01-01 03:17:15,903 [training] [INFO] training steps: 39000, Loss: 0.4614
2026-01-01 03:17:20,635 [training] [INFO] training steps: 39100, Loss: 0.4092
2026-01-01 03:17:25,360 [training] [INFO] training steps: 39200, Loss: 0.3680
2026-01-01 03:17:28,693 [training] [INFO] epoch 77 train loss:0.36423059129247476
2026-01-01 03:17:30,007 [training] [INFO] epoch 77 test loss:0.3724
2026-01-01 03:17:30,007 [training] [INFO] start training epochs 78
2026-01-01 03:17:31,993 [training] [INFO] training steps: 39300, Loss: 0.3927
2026-01-01 03:17:36,707 [training] [INFO] training steps: 39400, Loss: 0.4038
2026-01-01 03:17:41,416 [training] [INFO] training steps: 39500, Loss: 0.3657
2026-01-01 03:17:46,193 [training] [INFO] training steps: 39600, Loss: 0.2964
2026-01-01 03:17:51,029 [training] [INFO] training steps: 39700, Loss: 0.3408
2026-01-01 03:17:54,913 [training] [INFO] epoch 78 train loss:0.35607486782120723
2026-01-01 03:17:56,231 [training] [INFO] epoch 78 test loss:0.4396
2026-01-01 03:17:56,231 [training] [INFO] start training epochs 79
2026-01-01 03:17:57,742 [training] [INFO] training steps: 39800, Loss: 0.3459
2026-01-01 03:18:02,488 [training] [INFO] training steps: 39900, Loss: 0.3540
2026-01-01 03:18:07,218 [training] [INFO] training steps: 40000, Loss: 0.3733
2026-01-01 03:18:11,966 [training] [INFO] training steps: 40100, Loss: 0.3502
2026-01-01 03:18:16,702 [training] [INFO] training steps: 40200, Loss: 0.4163
2026-01-01 03:18:20,977 [training] [INFO] epoch 79 train loss:0.3488156352557388
2026-01-01 03:18:22,307 [training] [INFO] epoch 79 test loss:0.3544
2026-01-01 03:18:22,308 [training] [INFO] start training epochs 80
2026-01-01 03:18:23,362 [training] [INFO] training steps: 40300, Loss: 0.3462
2026-01-01 03:18:28,085 [training] [INFO] training steps: 40400, Loss: 0.2933
2026-01-01 03:18:32,814 [training] [INFO] training steps: 40500, Loss: 0.2790
2026-01-01 03:18:37,547 [training] [INFO] training steps: 40600, Loss: 0.2503
2026-01-01 03:18:42,284 [training] [INFO] training steps: 40700, Loss: 0.2861
2026-01-01 03:18:47,022 [training] [INFO] training steps: 40800, Loss: 0.3225
2026-01-01 03:18:47,045 [training] [INFO] epoch 80 train loss:0.3568935376171972
2026-01-01 03:18:48,351 [training] [INFO] epoch 80 test loss:0.3791
2026-01-01 03:18:48,351 [training] [INFO] start training epochs 81
2026-01-01 03:18:53,664 [training] [INFO] training steps: 40900, Loss: 0.3119
2026-01-01 03:18:58,425 [training] [INFO] training steps: 41000, Loss: 0.2923
2026-01-01 03:19:03,174 [training] [INFO] training steps: 41100, Loss: 0.3412
2026-01-01 03:19:07,898 [training] [INFO] training steps: 41200, Loss: 0.2718
2026-01-01 03:19:12,633 [training] [INFO] training steps: 41300, Loss: 0.3155
2026-01-01 03:19:13,134 [training] [INFO] epoch 81 train loss:0.3468225765462015
2026-01-01 03:19:14,437 [training] [INFO] epoch 81 test loss:0.3172
2026-01-01 03:19:14,437 [training] [INFO] start training epochs 82
2026-01-01 03:19:19,267 [training] [INFO] training steps: 41400, Loss: 0.2358
2026-01-01 03:19:24,123 [training] [INFO] training steps: 41500, Loss: 0.3648
2026-01-01 03:19:28,969 [training] [INFO] training steps: 41600, Loss: 0.3939
2026-01-01 03:19:33,780 [training] [INFO] training steps: 41700, Loss: 0.3639
2026-01-01 03:19:38,570 [training] [INFO] training steps: 41800, Loss: 0.3494
2026-01-01 03:19:39,555 [training] [INFO] epoch 82 train loss:0.344261549559294
2026-01-01 03:19:40,876 [training] [INFO] epoch 82 test loss:0.3799
2026-01-01 03:19:40,876 [training] [INFO] start training epochs 83
2026-01-01 03:19:45,238 [training] [INFO] training steps: 41900, Loss: 0.3471
2026-01-01 03:19:50,052 [training] [INFO] training steps: 42000, Loss: 0.2497
2026-01-01 03:19:54,839 [training] [INFO] training steps: 42100, Loss: 0.3178
2026-01-01 03:19:59,593 [training] [INFO] training steps: 42200, Loss: 0.4379
2026-01-01 03:20:04,393 [training] [INFO] training steps: 42300, Loss: 0.4177
2026-01-01 03:20:05,850 [training] [INFO] epoch 83 train loss:0.3413472069829118
2026-01-01 03:20:07,156 [training] [INFO] epoch 83 test loss:0.3476
2026-01-01 03:20:07,156 [training] [INFO] start training epochs 84
2026-01-01 03:20:11,028 [training] [INFO] training steps: 42400, Loss: 0.3202
2026-01-01 03:20:15,788 [training] [INFO] training steps: 42500, Loss: 0.3700
2026-01-01 03:20:20,542 [training] [INFO] training steps: 42600, Loss: 0.3144
2026-01-01 03:20:25,295 [training] [INFO] training steps: 42700, Loss: 0.2910
2026-01-01 03:20:30,041 [training] [INFO] training steps: 42800, Loss: 0.3019
2026-01-01 03:20:31,968 [training] [INFO] epoch 84 train loss:0.3417026226134861
2026-01-01 03:20:33,309 [training] [INFO] epoch 84 test loss:0.3312
2026-01-01 03:20:33,309 [training] [INFO] start training epochs 85
2026-01-01 03:20:36,733 [training] [INFO] training steps: 42900, Loss: 0.2379
2026-01-01 03:20:41,524 [training] [INFO] training steps: 43000, Loss: 0.4218
2026-01-01 03:20:46,298 [training] [INFO] training steps: 43100, Loss: 0.3674
2026-01-01 03:20:51,084 [training] [INFO] training steps: 43200, Loss: 0.2353
2026-01-01 03:20:55,838 [training] [INFO] training steps: 43300, Loss: 0.2837
2026-01-01 03:20:58,265 [training] [INFO] epoch 85 train loss:0.3548316741690916
2026-01-01 03:20:59,574 [training] [INFO] epoch 85 test loss:0.4358
2026-01-01 03:20:59,575 [training] [INFO] start training epochs 86
2026-01-01 03:21:02,489 [training] [INFO] training steps: 43400, Loss: 0.3863
2026-01-01 03:21:07,261 [training] [INFO] training steps: 43500, Loss: 0.4263
2026-01-01 03:21:12,043 [training] [INFO] training steps: 43600, Loss: 0.3911
2026-01-01 03:21:16,807 [training] [INFO] training steps: 43700, Loss: 0.2833
2026-01-01 03:21:21,600 [training] [INFO] training steps: 43800, Loss: 0.4193
2026-01-01 03:21:24,536 [training] [INFO] epoch 86 train loss:0.3475142595522544
2026-01-01 03:21:25,878 [training] [INFO] epoch 86 test loss:0.3461
2026-01-01 03:21:25,878 [training] [INFO] start training epochs 87
2026-01-01 03:21:28,357 [training] [INFO] training steps: 43900, Loss: 0.2992
2026-01-01 03:21:33,131 [training] [INFO] training steps: 44000, Loss: 0.4629
2026-01-01 03:21:37,898 [training] [INFO] training steps: 44100, Loss: 0.3101
2026-01-01 03:21:42,675 [training] [INFO] training steps: 44200, Loss: 0.3464
2026-01-01 03:21:47,427 [training] [INFO] training steps: 44300, Loss: 0.2763
2026-01-01 03:21:50,829 [training] [INFO] epoch 87 train loss:0.33583389611220826
2026-01-01 03:21:52,164 [training] [INFO] epoch 87 test loss:0.4533
2026-01-01 03:21:52,165 [training] [INFO] start training epochs 88
2026-01-01 03:21:54,143 [training] [INFO] training steps: 44400, Loss: 0.3323
2026-01-01 03:21:58,950 [training] [INFO] training steps: 44500, Loss: 0.3199
2026-01-01 03:22:03,744 [training] [INFO] training steps: 44600, Loss: 0.5092
2026-01-01 03:22:08,534 [training] [INFO] training steps: 44700, Loss: 0.3259
2026-01-01 03:22:13,348 [training] [INFO] training steps: 44800, Loss: 0.6019
2026-01-01 03:22:17,233 [training] [INFO] epoch 88 train loss:0.3404405671884032
2026-01-01 03:22:18,561 [training] [INFO] epoch 88 test loss:0.4497
2026-01-01 03:22:18,562 [training] [INFO] start training epochs 89
2026-01-01 03:22:20,082 [training] [INFO] training steps: 44900, Loss: 0.2715
2026-01-01 03:22:24,858 [training] [INFO] training steps: 45000, Loss: 0.3448
2026-01-01 03:22:29,634 [training] [INFO] training steps: 45100, Loss: 0.3712
2026-01-01 03:22:34,397 [training] [INFO] training steps: 45200, Loss: 0.3716
2026-01-01 03:22:39,185 [training] [INFO] training steps: 45300, Loss: 0.3230
2026-01-01 03:22:43,494 [training] [INFO] epoch 89 train loss:0.341192082593254
2026-01-01 03:22:44,817 [training] [INFO] epoch 89 test loss:0.3708
2026-01-01 03:22:44,817 [training] [INFO] start training epochs 90
2026-01-01 03:22:45,859 [training] [INFO] training steps: 45400, Loss: 0.3624
2026-01-01 03:22:50,633 [training] [INFO] training steps: 45500, Loss: 0.4626
2026-01-01 03:22:55,384 [training] [INFO] training steps: 45600, Loss: 0.3111
2026-01-01 03:23:00,170 [training] [INFO] training steps: 45700, Loss: 0.3277
2026-01-01 03:23:04,948 [training] [INFO] training steps: 45800, Loss: 0.3936
2026-01-01 03:23:09,729 [training] [INFO] training steps: 45900, Loss: 0.2807
2026-01-01 03:23:09,761 [training] [INFO] epoch 90 train loss:0.3428130883504363
2026-01-01 03:23:11,063 [training] [INFO] epoch 90 test loss:0.3665
2026-01-01 03:23:11,063 [training] [INFO] start training epochs 91
2026-01-01 03:23:16,447 [training] [INFO] training steps: 46000, Loss: 0.3909
2026-01-01 03:23:21,278 [training] [INFO] training steps: 46100, Loss: 0.3842
2026-01-01 03:23:26,068 [training] [INFO] training steps: 46200, Loss: 0.4087
2026-01-01 03:23:30,840 [training] [INFO] training steps: 46300, Loss: 0.4466
2026-01-01 03:23:35,618 [training] [INFO] training steps: 46400, Loss: 0.3895
2026-01-01 03:23:36,128 [training] [INFO] epoch 91 train loss:0.33586275095448775
2026-01-01 03:23:37,514 [training] [INFO] epoch 91 test loss:0.4130
2026-01-01 03:23:37,514 [training] [INFO] start training epochs 92
2026-01-01 03:23:42,325 [training] [INFO] training steps: 46500, Loss: 0.3366
2026-01-01 03:23:47,067 [training] [INFO] training steps: 46600, Loss: 0.3027
2026-01-01 03:23:51,804 [training] [INFO] training steps: 46700, Loss: 0.2914
2026-01-01 03:23:56,526 [training] [INFO] training steps: 46800, Loss: 0.3053
2026-01-01 03:24:01,262 [training] [INFO] training steps: 46900, Loss: 0.3258
2026-01-01 03:24:02,246 [training] [INFO] epoch 92 train loss:0.32777863524708095
2026-01-01 03:24:03,572 [training] [INFO] epoch 92 test loss:0.4319
2026-01-01 03:24:03,573 [training] [INFO] start training epochs 93
2026-01-01 03:24:07,921 [training] [INFO] training steps: 47000, Loss: 0.2581
2026-01-01 03:24:12,664 [training] [INFO] training steps: 47100, Loss: 0.3544
2026-01-01 03:24:17,420 [training] [INFO] training steps: 47200, Loss: 0.3633
2026-01-01 03:24:22,154 [training] [INFO] training steps: 47300, Loss: 0.2769
2026-01-01 03:24:26,916 [training] [INFO] training steps: 47400, Loss: 0.3805
2026-01-01 03:24:28,363 [training] [INFO] epoch 93 train loss:0.3379783566675934
2026-01-01 03:24:29,683 [training] [INFO] epoch 93 test loss:0.4580
2026-01-01 03:24:29,684 [training] [INFO] start training epochs 94
2026-01-01 03:24:33,558 [training] [INFO] training steps: 47500, Loss: 0.2660
2026-01-01 03:24:38,297 [training] [INFO] training steps: 47600, Loss: 0.3986
2026-01-01 03:24:43,050 [training] [INFO] training steps: 47700, Loss: 0.2882
2026-01-01 03:24:47,774 [training] [INFO] training steps: 47800, Loss: 0.3165
2026-01-01 03:24:52,503 [training] [INFO] training steps: 47900, Loss: 0.3191
2026-01-01 03:24:54,411 [training] [INFO] epoch 94 train loss:0.32711303377268364
2026-01-01 03:24:55,720 [training] [INFO] epoch 94 test loss:0.3243
2026-01-01 03:24:55,720 [training] [INFO] start training epochs 95
2026-01-01 03:24:59,094 [training] [INFO] training steps: 48000, Loss: 0.3634
2026-01-01 03:25:03,890 [training] [INFO] training steps: 48100, Loss: 0.2550
2026-01-01 03:25:08,657 [training] [INFO] training steps: 48200, Loss: 0.3493
2026-01-01 03:25:13,422 [training] [INFO] training steps: 48300, Loss: 0.3102
2026-01-01 03:25:18,173 [training] [INFO] training steps: 48400, Loss: 0.4434
2026-01-01 03:25:20,610 [training] [INFO] epoch 95 train loss:0.32507136429057404
2026-01-01 03:25:21,945 [training] [INFO] epoch 95 test loss:0.3854
2026-01-01 03:25:21,945 [training] [INFO] start training epochs 96
2026-01-01 03:25:24,880 [training] [INFO] training steps: 48500, Loss: 0.3045
2026-01-01 03:25:29,647 [training] [INFO] training steps: 48600, Loss: 0.3840
2026-01-01 03:25:34,423 [training] [INFO] training steps: 48700, Loss: 0.2683
2026-01-01 03:25:39,187 [training] [INFO] training steps: 48800, Loss: 0.2847
2026-01-01 03:25:43,950 [training] [INFO] training steps: 48900, Loss: 0.3212
2026-01-01 03:25:46,822 [training] [INFO] epoch 96 train loss:0.33471322901108685
2026-01-01 03:25:48,146 [training] [INFO] epoch 96 test loss:0.4749
2026-01-01 03:25:48,146 [training] [INFO] start training epochs 97
2026-01-01 03:25:50,586 [training] [INFO] training steps: 49000, Loss: 0.3123
2026-01-01 03:25:55,319 [training] [INFO] training steps: 49100, Loss: 0.3303
2026-01-01 03:26:00,063 [training] [INFO] training steps: 49200, Loss: 0.2592
2026-01-01 03:26:04,810 [training] [INFO] training steps: 49300, Loss: 0.3421
2026-01-01 03:26:09,554 [training] [INFO] training steps: 49400, Loss: 0.3228
2026-01-01 03:26:12,916 [training] [INFO] epoch 97 train loss:0.3294856683004136
2026-01-01 03:26:14,216 [training] [INFO] epoch 97 test loss:0.3408
2026-01-01 03:26:14,216 [training] [INFO] start training epochs 98
2026-01-01 03:26:16,219 [training] [INFO] training steps: 49500, Loss: 0.3335
2026-01-01 03:26:21,004 [training] [INFO] training steps: 49600, Loss: 0.3094
2026-01-01 03:26:25,778 [training] [INFO] training steps: 49700, Loss: 0.2299
2026-01-01 03:26:30,552 [training] [INFO] training steps: 49800, Loss: 0.3472
2026-01-01 03:26:35,314 [training] [INFO] training steps: 49900, Loss: 0.3057
2026-01-01 03:26:39,149 [training] [INFO] epoch 98 train loss:0.3188128055895076
2026-01-01 03:26:40,429 [training] [INFO] epoch 98 test loss:0.3235
2026-01-01 03:26:40,429 [training] [INFO] start training epochs 99
2026-01-01 03:26:41,928 [training] [INFO] training steps: 50000, Loss: 0.3025
2026-01-01 03:26:46,704 [training] [INFO] training steps: 50100, Loss: 0.2972
2026-01-01 03:26:51,486 [training] [INFO] training steps: 50200, Loss: 0.2800
2026-01-01 03:26:56,256 [training] [INFO] training steps: 50300, Loss: 0.3849
2026-01-01 03:27:01,015 [training] [INFO] training steps: 50400, Loss: 0.3846
2026-01-01 03:27:05,333 [training] [INFO] epoch 99 train loss:0.31993575727238377
2026-01-01 03:27:06,662 [training] [INFO] epoch 99 test loss:0.3333
2026-01-01 03:27:06,663 [training] [INFO] start training epochs 100
2026-01-01 03:27:07,690 [training] [INFO] training steps: 50500, Loss: 0.3553
2026-01-01 03:27:12,406 [training] [INFO] training steps: 50600, Loss: 0.2508
2026-01-01 03:27:17,119 [training] [INFO] training steps: 50700, Loss: 0.2794
2026-01-01 03:27:21,836 [training] [INFO] training steps: 50800, Loss: 0.3277
2026-01-01 03:27:26,554 [training] [INFO] training steps: 50900, Loss: 0.2387
2026-01-01 03:27:31,278 [training] [INFO] training steps: 51000, Loss: 0.2824
2026-01-01 03:27:31,301 [training] [INFO] epoch 100 train loss:0.31608468259082123
2026-01-01 03:27:32,601 [training] [INFO] epoch 100 test loss:0.3892
2026-01-01 03:27:32,602 [training] [INFO] start training epochs 101
2026-01-01 03:27:37,848 [training] [INFO] training steps: 51100, Loss: 0.2503
2026-01-01 03:27:42,556 [training] [INFO] training steps: 51200, Loss: 0.2753
2026-01-01 03:27:47,264 [training] [INFO] training steps: 51300, Loss: 0.3003
2026-01-01 03:27:51,971 [training] [INFO] training steps: 51400, Loss: 0.4021
2026-01-01 03:27:56,684 [training] [INFO] training steps: 51500, Loss: 0.2963
2026-01-01 03:27:57,191 [training] [INFO] epoch 101 train loss:0.3140336046031877
2026-01-01 03:27:58,512 [training] [INFO] epoch 101 test loss:0.3061
2026-01-01 03:27:58,512 [training] [INFO] start training epochs 102
2026-01-01 03:28:03,309 [training] [INFO] training steps: 51600, Loss: 0.2395
2026-01-01 03:28:08,017 [training] [INFO] training steps: 51700, Loss: 0.3831
2026-01-01 03:28:12,724 [training] [INFO] training steps: 51800, Loss: 0.3481
2026-01-01 03:28:17,440 [training] [INFO] training steps: 51900, Loss: 0.3367
2026-01-01 03:28:22,156 [training] [INFO] training steps: 52000, Loss: 0.3650
2026-01-01 03:28:23,130 [training] [INFO] epoch 102 train loss:0.3248968191883143
2026-01-01 03:28:24,438 [training] [INFO] epoch 102 test loss:0.3858
2026-01-01 03:28:24,439 [training] [INFO] start training epochs 103
2026-01-01 03:28:28,719 [training] [INFO] training steps: 52100, Loss: 0.2713
2026-01-01 03:28:33,418 [training] [INFO] training steps: 52200, Loss: 0.2755
2026-01-01 03:28:38,118 [training] [INFO] training steps: 52300, Loss: 0.2858
2026-01-01 03:28:42,818 [training] [INFO] training steps: 52400, Loss: 0.3127
2026-01-01 03:28:47,521 [training] [INFO] training steps: 52500, Loss: 0.2733
2026-01-01 03:28:48,965 [training] [INFO] epoch 103 train loss:0.31356769692079695
2026-01-01 03:28:50,259 [training] [INFO] epoch 103 test loss:0.3192
2026-01-01 03:28:50,259 [training] [INFO] start training epochs 104
2026-01-01 03:28:54,089 [training] [INFO] training steps: 52600, Loss: 0.2802
2026-01-01 03:28:58,801 [training] [INFO] training steps: 52700, Loss: 0.2600
2026-01-01 03:29:03,518 [training] [INFO] training steps: 52800, Loss: 0.2809
2026-01-01 03:29:08,235 [training] [INFO] training steps: 52900, Loss: 0.2174
2026-01-01 03:29:12,945 [training] [INFO] training steps: 53000, Loss: 0.3015
2026-01-01 03:29:14,856 [training] [INFO] epoch 104 train loss:0.3126166778744436
2026-01-01 03:29:16,150 [training] [INFO] epoch 104 test loss:0.3691
2026-01-01 03:29:16,151 [training] [INFO] start training epochs 105
2026-01-01 03:29:19,524 [training] [INFO] training steps: 53100, Loss: 0.3032
2026-01-01 03:29:24,217 [training] [INFO] training steps: 53200, Loss: 0.2857
2026-01-01 03:29:28,911 [training] [INFO] training steps: 53300, Loss: 0.4736
2026-01-01 03:29:33,602 [training] [INFO] training steps: 53400, Loss: 0.3459
2026-01-01 03:29:38,297 [training] [INFO] training steps: 53500, Loss: 0.2643
2026-01-01 03:29:40,677 [training] [INFO] epoch 105 train loss:0.32501523246367775
2026-01-01 03:29:41,975 [training] [INFO] epoch 105 test loss:0.3757
2026-01-01 03:29:41,975 [training] [INFO] start training epochs 106
2026-01-01 03:29:44,894 [training] [INFO] training steps: 53600, Loss: 0.2774
2026-01-01 03:29:49,601 [training] [INFO] training steps: 53700, Loss: 0.3043
2026-01-01 03:29:54,312 [training] [INFO] training steps: 53800, Loss: 0.2920
2026-01-01 03:29:59,025 [training] [INFO] training steps: 53900, Loss: 0.3378
2026-01-01 03:30:03,735 [training] [INFO] training steps: 54000, Loss: 0.2912
2026-01-01 03:30:06,590 [training] [INFO] epoch 106 train loss:0.31071975751250397
2026-01-01 03:30:07,914 [training] [INFO] epoch 106 test loss:0.3643
2026-01-01 03:30:07,914 [training] [INFO] start training epochs 107
2026-01-01 03:30:10,367 [training] [INFO] training steps: 54100, Loss: 0.2341
2026-01-01 03:30:15,081 [training] [INFO] training steps: 54200, Loss: 0.2502
2026-01-01 03:30:19,786 [training] [INFO] training steps: 54300, Loss: 0.3242
2026-01-01 03:30:24,484 [training] [INFO] training steps: 54400, Loss: 0.3942
2026-01-01 03:30:29,182 [training] [INFO] training steps: 54500, Loss: 0.4655
2026-01-01 03:30:32,509 [training] [INFO] epoch 107 train loss:0.3133806437838311
2026-01-01 03:30:33,843 [training] [INFO] epoch 107 test loss:0.3350
2026-01-01 03:30:33,844 [training] [INFO] start training epochs 108
2026-01-01 03:30:35,822 [training] [INFO] training steps: 54600, Loss: 0.4128
2026-01-01 03:30:40,534 [training] [INFO] training steps: 54700, Loss: 0.3025
2026-01-01 03:30:45,246 [training] [INFO] training steps: 54800, Loss: 0.2945
2026-01-01 03:30:49,963 [training] [INFO] training steps: 54900, Loss: 0.2916
2026-01-01 03:30:54,676 [training] [INFO] training steps: 55000, Loss: 0.2497
2026-01-01 03:30:58,476 [training] [INFO] epoch 108 train loss:0.31547926328345843
2026-01-01 03:30:59,785 [training] [INFO] epoch 108 test loss:0.3363
2026-01-01 03:30:59,785 [training] [INFO] start training epochs 109
2026-01-01 03:31:01,274 [training] [INFO] training steps: 55100, Loss: 0.2958
2026-01-01 03:31:05,983 [training] [INFO] training steps: 55200, Loss: 0.2704
2026-01-01 03:31:10,688 [training] [INFO] training steps: 55300, Loss: 0.4309
2026-01-01 03:31:15,374 [training] [INFO] training steps: 55400, Loss: 0.2752
2026-01-01 03:31:20,060 [training] [INFO] training steps: 55500, Loss: 0.3316
2026-01-01 03:31:24,310 [training] [INFO] epoch 109 train loss:0.3163265267423555
2026-01-01 03:31:25,612 [training] [INFO] epoch 109 test loss:0.3392
2026-01-01 03:31:25,612 [training] [INFO] start training epochs 110
2026-01-01 03:31:26,622 [training] [INFO] training steps: 55600, Loss: 0.3597
2026-01-01 03:31:31,309 [training] [INFO] training steps: 55700, Loss: 0.2798
2026-01-01 03:31:35,996 [training] [INFO] training steps: 55800, Loss: 0.3387
2026-01-01 03:31:40,686 [training] [INFO] training steps: 55900, Loss: 0.5505
2026-01-01 03:31:45,376 [training] [INFO] training steps: 56000, Loss: 0.3327
2026-01-01 03:31:50,073 [training] [INFO] training steps: 56100, Loss: 0.3390
2026-01-01 03:31:50,096 [training] [INFO] epoch 110 train loss:0.3185266718852754
2026-01-01 03:31:51,389 [training] [INFO] epoch 110 test loss:0.3033
2026-01-01 03:31:51,390 [training] [INFO] start training epochs 111
2026-01-01 03:31:56,645 [training] [INFO] training steps: 56200, Loss: 0.3794
2026-01-01 03:32:01,340 [training] [INFO] training steps: 56300, Loss: 0.3663
2026-01-01 03:32:06,036 [training] [INFO] training steps: 56400, Loss: 0.2466
2026-01-01 03:32:10,737 [training] [INFO] training steps: 56500, Loss: 0.2818
2026-01-01 03:32:15,458 [training] [INFO] training steps: 56600, Loss: 0.2646
2026-01-01 03:32:15,958 [training] [INFO] epoch 111 train loss:0.31044734526498646
2026-01-01 03:32:17,264 [training] [INFO] epoch 111 test loss:0.3258
2026-01-01 03:32:17,264 [training] [INFO] start training epochs 112
2026-01-01 03:32:22,040 [training] [INFO] training steps: 56700, Loss: 0.3193
2026-01-01 03:32:26,758 [training] [INFO] training steps: 56800, Loss: 0.3997
2026-01-01 03:32:31,475 [training] [INFO] training steps: 56900, Loss: 0.3819
2026-01-01 03:32:36,192 [training] [INFO] training steps: 57000, Loss: 0.3321
2026-01-01 03:32:40,907 [training] [INFO] training steps: 57100, Loss: 0.3620
2026-01-01 03:32:41,880 [training] [INFO] epoch 112 train loss:0.3085139133474406
2026-01-01 03:32:43,194 [training] [INFO] epoch 112 test loss:0.3289
2026-01-01 03:32:43,194 [training] [INFO] start training epochs 113
2026-01-01 03:32:47,515 [training] [INFO] training steps: 57200, Loss: 0.3317
2026-01-01 03:32:52,236 [training] [INFO] training steps: 57300, Loss: 0.3603
2026-01-01 03:32:56,955 [training] [INFO] training steps: 57400, Loss: 0.3103
2026-01-01 03:33:01,674 [training] [INFO] training steps: 57500, Loss: 0.2523
2026-01-01 03:33:06,396 [training] [INFO] training steps: 57600, Loss: 0.2831
2026-01-01 03:33:07,840 [training] [INFO] epoch 113 train loss:0.30359683422481315
2026-01-01 03:33:09,151 [training] [INFO] epoch 113 test loss:0.3156
2026-01-01 03:33:09,151 [training] [INFO] start training epochs 114
2026-01-01 03:33:12,988 [training] [INFO] training steps: 57700, Loss: 0.2674
2026-01-01 03:33:17,677 [training] [INFO] training steps: 57800, Loss: 0.2507
2026-01-01 03:33:22,368 [training] [INFO] training steps: 57900, Loss: 0.2724
2026-01-01 03:33:27,061 [training] [INFO] training steps: 58000, Loss: 0.3328
2026-01-01 03:33:31,751 [training] [INFO] training steps: 58100, Loss: 0.3051
2026-01-01 03:33:33,657 [training] [INFO] epoch 114 train loss:0.3058911169276518
2026-01-01 03:33:34,982 [training] [INFO] epoch 114 test loss:0.2935
2026-01-01 03:33:34,982 [training] [INFO] start training epochs 115
2026-01-01 03:33:38,350 [training] [INFO] training steps: 58200, Loss: 0.2340
2026-01-01 03:33:43,070 [training] [INFO] training steps: 58300, Loss: 0.3314
2026-01-01 03:33:47,789 [training] [INFO] training steps: 58400, Loss: 0.2404
2026-01-01 03:33:52,507 [training] [INFO] training steps: 58500, Loss: 0.3698
2026-01-01 03:33:57,227 [training] [INFO] training steps: 58600, Loss: 0.4107
2026-01-01 03:33:59,615 [training] [INFO] epoch 115 train loss:0.30659126864344466
2026-01-01 03:34:00,915 [training] [INFO] epoch 115 test loss:0.3129
2026-01-01 03:34:00,915 [training] [INFO] start training epochs 116
2026-01-01 03:34:03,812 [training] [INFO] training steps: 58700, Loss: 0.3337
2026-01-01 03:34:08,504 [training] [INFO] training steps: 58800, Loss: 0.3075
2026-01-01 03:34:13,202 [training] [INFO] training steps: 58900, Loss: 0.2751
2026-01-01 03:34:17,899 [training] [INFO] training steps: 59000, Loss: 0.2739
2026-01-01 03:34:22,597 [training] [INFO] training steps: 59100, Loss: 0.3817
2026-01-01 03:34:25,441 [training] [INFO] epoch 116 train loss:0.30727745878930185
2026-01-01 03:34:26,760 [training] [INFO] epoch 116 test loss:0.3446
2026-01-01 03:34:26,760 [training] [INFO] start training epochs 117
2026-01-01 03:34:29,229 [training] [INFO] training steps: 59200, Loss: 0.3308
2026-01-01 03:34:33,962 [training] [INFO] training steps: 59300, Loss: 0.2668
2026-01-01 03:34:38,691 [training] [INFO] training steps: 59400, Loss: 0.3410
2026-01-01 03:34:43,420 [training] [INFO] training steps: 59500, Loss: 0.2243
2026-01-01 03:34:48,151 [training] [INFO] training steps: 59600, Loss: 0.2689
2026-01-01 03:34:51,494 [training] [INFO] epoch 117 train loss:0.2998207649471713
2026-01-01 03:34:52,842 [training] [INFO] epoch 117 test loss:0.3257
2026-01-01 03:34:52,842 [training] [INFO] start training epochs 118
2026-01-01 03:34:54,795 [training] [INFO] training steps: 59700, Loss: 0.3573
2026-01-01 03:34:59,495 [training] [INFO] training steps: 59800, Loss: 0.3282
2026-01-01 03:35:04,197 [training] [INFO] training steps: 59900, Loss: 0.2983
2026-01-01 03:35:08,904 [training] [INFO] training steps: 60000, Loss: 0.2677
2026-01-01 03:35:13,606 [training] [INFO] training steps: 60100, Loss: 0.3050
2026-01-01 03:35:17,398 [training] [INFO] epoch 118 train loss:0.3095468459176082
2026-01-01 03:35:18,716 [training] [INFO] epoch 118 test loss:0.3399
2026-01-01 03:35:18,717 [training] [INFO] start training epochs 119
2026-01-01 03:35:20,193 [training] [INFO] training steps: 60200, Loss: 0.3396
2026-01-01 03:35:24,892 [training] [INFO] training steps: 60300, Loss: 0.3338
2026-01-01 03:35:29,587 [training] [INFO] training steps: 60400, Loss: 0.3227
2026-01-01 03:35:34,283 [training] [INFO] training steps: 60500, Loss: 0.3427
2026-01-01 03:35:38,978 [training] [INFO] training steps: 60600, Loss: 0.3094
2026-01-01 03:35:43,240 [training] [INFO] epoch 119 train loss:0.2980105297238219
2026-01-01 03:35:44,542 [training] [INFO] epoch 119 test loss:0.4253
2026-01-01 03:35:44,543 [training] [INFO] start training epochs 120
2026-01-01 03:35:45,584 [training] [INFO] training steps: 60700, Loss: 0.3185
2026-01-01 03:35:50,314 [training] [INFO] training steps: 60800, Loss: 0.2822
2026-01-01 03:35:55,045 [training] [INFO] training steps: 60900, Loss: 0.3066
2026-01-01 03:35:59,783 [training] [INFO] training steps: 61000, Loss: 0.2599
2026-01-01 03:36:04,518 [training] [INFO] training steps: 61100, Loss: 0.3872
2026-01-01 03:36:09,259 [training] [INFO] training steps: 61200, Loss: 0.2738
2026-01-01 03:36:09,282 [training] [INFO] epoch 120 train loss:0.3078782390730054
2026-01-01 03:36:10,596 [training] [INFO] epoch 120 test loss:0.2876
2026-01-01 03:36:10,597 [training] [INFO] start training epochs 121
2026-01-01 03:36:15,829 [training] [INFO] training steps: 61300, Loss: 0.2518
2026-01-01 03:36:20,525 [training] [INFO] training steps: 61400, Loss: 0.3682
2026-01-01 03:36:25,217 [training] [INFO] training steps: 61500, Loss: 0.2570
2026-01-01 03:36:29,909 [training] [INFO] training steps: 61600, Loss: 0.2922
2026-01-01 03:36:34,603 [training] [INFO] training steps: 61700, Loss: 0.3213
2026-01-01 03:36:35,104 [training] [INFO] epoch 121 train loss:0.2986800573620142
2026-01-01 03:36:36,398 [training] [INFO] epoch 121 test loss:0.3071
2026-01-01 03:36:36,399 [training] [INFO] start training epochs 122
2026-01-01 03:36:41,222 [training] [INFO] training steps: 61800, Loss: 0.4162
2026-01-01 03:36:45,936 [training] [INFO] training steps: 61900, Loss: 0.3239
2026-01-01 03:36:50,657 [training] [INFO] training steps: 62000, Loss: 0.2596
2026-01-01 03:36:55,375 [training] [INFO] training steps: 62100, Loss: 0.2493
2026-01-01 03:37:00,092 [training] [INFO] training steps: 62200, Loss: 0.2805
2026-01-01 03:37:01,062 [training] [INFO] epoch 122 train loss:0.3094549744444735
2026-01-01 03:37:02,385 [training] [INFO] epoch 122 test loss:0.3189
2026-01-01 03:37:02,386 [training] [INFO] start training epochs 123
2026-01-01 03:37:06,703 [training] [INFO] training steps: 62300, Loss: 0.2906
2026-01-01 03:37:11,417 [training] [INFO] training steps: 62400, Loss: 0.3002
2026-01-01 03:37:16,131 [training] [INFO] training steps: 62500, Loss: 0.2808
2026-01-01 03:37:20,842 [training] [INFO] training steps: 62600, Loss: 0.2664
2026-01-01 03:37:25,561 [training] [INFO] training steps: 62700, Loss: 0.3063
2026-01-01 03:37:27,003 [training] [INFO] epoch 123 train loss:0.2933685014353079
2026-01-01 03:37:28,284 [training] [INFO] epoch 123 test loss:0.2712
2026-01-01 03:37:28,285 [training] [INFO] start training epochs 124
2026-01-01 03:37:32,140 [training] [INFO] training steps: 62800, Loss: 0.3226
2026-01-01 03:37:36,873 [training] [INFO] training steps: 62900, Loss: 0.3559
2026-01-01 03:37:41,610 [training] [INFO] training steps: 63000, Loss: 0.2662
2026-01-01 03:37:46,349 [training] [INFO] training steps: 63100, Loss: 0.2816
2026-01-01 03:37:51,087 [training] [INFO] training steps: 63200, Loss: 0.3593
2026-01-01 03:37:53,010 [training] [INFO] epoch 124 train loss:0.29029466679283217
2026-01-01 03:37:54,327 [training] [INFO] epoch 124 test loss:0.3961
2026-01-01 03:37:54,327 [training] [INFO] start training epochs 125
2026-01-01 03:37:57,670 [training] [INFO] training steps: 63300, Loss: 0.2599
2026-01-01 03:38:02,369 [training] [INFO] training steps: 63400, Loss: 0.3188
2026-01-01 03:38:07,064 [training] [INFO] training steps: 63500, Loss: 0.2243
2026-01-01 03:38:11,756 [training] [INFO] training steps: 63600, Loss: 0.3392
2026-01-01 03:38:16,449 [training] [INFO] training steps: 63700, Loss: 0.3288
2026-01-01 03:38:18,828 [training] [INFO] epoch 125 train loss:0.3036583962978101
2026-01-01 03:38:20,132 [training] [INFO] epoch 125 test loss:0.2886
2026-01-01 03:38:20,133 [training] [INFO] start training epochs 126
2026-01-01 03:38:23,042 [training] [INFO] training steps: 63800, Loss: 0.2971
2026-01-01 03:38:27,762 [training] [INFO] training steps: 63900, Loss: 0.2891
2026-01-01 03:38:32,473 [training] [INFO] training steps: 64000, Loss: 0.2652
2026-01-01 03:38:37,174 [training] [INFO] training steps: 64100, Loss: 0.2974
2026-01-01 03:38:41,874 [training] [INFO] training steps: 64200, Loss: 0.3148
2026-01-01 03:38:44,725 [training] [INFO] epoch 126 train loss:0.29136250010308096
2026-01-01 03:38:46,028 [training] [INFO] epoch 126 test loss:0.3301
2026-01-01 03:38:46,028 [training] [INFO] start training epochs 127
2026-01-01 03:38:48,464 [training] [INFO] training steps: 64300, Loss: 0.4412
2026-01-01 03:38:53,163 [training] [INFO] training steps: 64400, Loss: 0.2879
2026-01-01 03:38:57,861 [training] [INFO] training steps: 64500, Loss: 0.2454
2026-01-01 03:39:02,557 [training] [INFO] training steps: 64600, Loss: 0.3866
2026-01-01 03:39:07,255 [training] [INFO] training steps: 64700, Loss: 0.2875
2026-01-01 03:39:10,573 [training] [INFO] epoch 127 train loss:0.2913024413527227
2026-01-01 03:39:11,876 [training] [INFO] epoch 127 test loss:0.3421
2026-01-01 03:39:11,877 [training] [INFO] start training epochs 128
2026-01-01 03:39:13,864 [training] [INFO] training steps: 64800, Loss: 0.3173
2026-01-01 03:39:18,583 [training] [INFO] training steps: 64900, Loss: 0.2882
2026-01-01 03:39:23,307 [training] [INFO] training steps: 65000, Loss: 0.2888
2026-01-01 03:39:28,028 [training] [INFO] training steps: 65100, Loss: 0.2216
2026-01-01 03:39:32,749 [training] [INFO] training steps: 65200, Loss: 0.2238
2026-01-01 03:39:36,559 [training] [INFO] epoch 128 train loss:0.2936367481362586
2026-01-01 03:39:37,885 [training] [INFO] epoch 128 test loss:0.3134
2026-01-01 03:39:37,885 [training] [INFO] start training epochs 129
2026-01-01 03:39:39,382 [training] [INFO] training steps: 65300, Loss: 0.2905
2026-01-01 03:39:44,106 [training] [INFO] training steps: 65400, Loss: 0.2337
2026-01-01 03:39:48,827 [training] [INFO] training steps: 65500, Loss: 0.3207
2026-01-01 03:39:53,549 [training] [INFO] training steps: 65600, Loss: 0.3123
2026-01-01 03:39:58,273 [training] [INFO] training steps: 65700, Loss: 0.2926
2026-01-01 03:40:02,624 [training] [INFO] epoch 129 train loss:0.28653505464979245
2026-01-01 03:40:03,928 [training] [INFO] epoch 129 test loss:0.3035
2026-01-01 03:40:03,928 [training] [INFO] start training epochs 130
2026-01-01 03:40:04,928 [training] [INFO] training steps: 65800, Loss: 0.3374
2026-01-01 03:40:09,637 [training] [INFO] training steps: 65900, Loss: 0.2333
2026-01-01 03:40:14,347 [training] [INFO] training steps: 66000, Loss: 0.2785
2026-01-01 03:40:19,057 [training] [INFO] training steps: 66100, Loss: 0.3183
2026-01-01 03:40:23,768 [training] [INFO] training steps: 66200, Loss: 0.3579
2026-01-01 03:40:28,537 [training] [INFO] training steps: 66300, Loss: 0.2855
2026-01-01 03:40:28,566 [training] [INFO] epoch 130 train loss:0.29255427995733185
2026-01-01 03:40:29,881 [training] [INFO] epoch 130 test loss:0.3797
2026-01-01 03:40:29,881 [training] [INFO] start training epochs 131
2026-01-01 03:40:35,108 [training] [INFO] training steps: 66400, Loss: 0.2329
2026-01-01 03:40:39,803 [training] [INFO] training steps: 66500, Loss: 0.2297
2026-01-01 03:40:44,498 [training] [INFO] training steps: 66600, Loss: 0.2655
2026-01-01 03:40:49,246 [training] [INFO] training steps: 66700, Loss: 0.2706
2026-01-01 03:40:53,936 [training] [INFO] training steps: 66800, Loss: 0.3000
2026-01-01 03:40:54,435 [training] [INFO] epoch 131 train loss:0.29153532081959294
2026-01-01 03:40:55,754 [training] [INFO] epoch 131 test loss:0.3074
2026-01-01 03:40:55,754 [training] [INFO] start training epochs 132
2026-01-01 03:41:00,589 [training] [INFO] training steps: 66900, Loss: 0.2084
2026-01-01 03:41:05,325 [training] [INFO] training steps: 67000, Loss: 0.2707
2026-01-01 03:41:10,125 [training] [INFO] training steps: 67100, Loss: 0.2689
2026-01-01 03:41:14,854 [training] [INFO] training steps: 67200, Loss: 0.3524
2026-01-01 03:41:19,581 [training] [INFO] training steps: 67300, Loss: 0.2992
2026-01-01 03:41:20,565 [training] [INFO] epoch 132 train loss:0.28771255697105447
2026-01-01 03:41:21,873 [training] [INFO] epoch 132 test loss:0.3257
2026-01-01 03:41:21,874 [training] [INFO] start training epochs 133
2026-01-01 03:41:26,138 [training] [INFO] training steps: 67400, Loss: 0.2991
2026-01-01 03:41:30,835 [training] [INFO] training steps: 67500, Loss: 0.2715
2026-01-01 03:41:35,607 [training] [INFO] training steps: 67600, Loss: 0.3131
2026-01-01 03:41:40,292 [training] [INFO] training steps: 67700, Loss: 0.2834
2026-01-01 03:41:44,980 [training] [INFO] training steps: 67800, Loss: 0.3194
2026-01-01 03:41:46,424 [training] [INFO] epoch 133 train loss:0.2850649757128136
2026-01-01 03:41:47,756 [training] [INFO] epoch 133 test loss:0.3282
2026-01-01 03:41:47,756 [training] [INFO] start training epochs 134
2026-01-01 03:41:51,588 [training] [INFO] training steps: 67900, Loss: 0.2002
2026-01-01 03:41:56,346 [training] [INFO] training steps: 68000, Loss: 0.3118
2026-01-01 03:42:01,039 [training] [INFO] training steps: 68100, Loss: 0.2379
2026-01-01 03:42:05,734 [training] [INFO] training steps: 68200, Loss: 0.2497
2026-01-01 03:42:10,429 [training] [INFO] training steps: 68300, Loss: 0.2358
2026-01-01 03:42:12,349 [training] [INFO] epoch 134 train loss:0.2892329044493974
2026-01-01 03:42:13,641 [training] [INFO] epoch 134 test loss:0.3190
2026-01-01 03:42:13,641 [training] [INFO] start training epochs 135
2026-01-01 03:42:17,008 [training] [INFO] training steps: 68400, Loss: 0.3578
2026-01-01 03:42:21,774 [training] [INFO] training steps: 68500, Loss: 0.2273
2026-01-01 03:42:26,466 [training] [INFO] training steps: 68600, Loss: 0.2811
2026-01-01 03:42:31,157 [training] [INFO] training steps: 68700, Loss: 0.1813
2026-01-01 03:42:35,848 [training] [INFO] training steps: 68800, Loss: 0.2893
2026-01-01 03:42:38,235 [training] [INFO] epoch 135 train loss:0.2823710256347469
2026-01-01 03:42:39,655 [training] [INFO] epoch 135 test loss:0.2832
2026-01-01 03:42:39,655 [training] [INFO] start training epochs 136
2026-01-01 03:42:42,678 [training] [INFO] training steps: 68900, Loss: 0.2282
2026-01-01 03:42:47,484 [training] [INFO] training steps: 69000, Loss: 0.2893
2026-01-01 03:42:52,191 [training] [INFO] training steps: 69100, Loss: 0.3231
2026-01-01 03:42:56,901 [training] [INFO] training steps: 69200, Loss: 0.3520
2026-01-01 03:43:01,611 [training] [INFO] training steps: 69300, Loss: 0.3205
2026-01-01 03:43:04,467 [training] [INFO] epoch 136 train loss:0.2837460219860077
2026-01-01 03:43:05,776 [training] [INFO] epoch 136 test loss:0.2874
2026-01-01 03:43:05,776 [training] [INFO] start training epochs 137
2026-01-01 03:43:08,229 [training] [INFO] training steps: 69400, Loss: 0.2958
2026-01-01 03:43:12,958 [training] [INFO] training steps: 69500, Loss: 0.2741
2026-01-01 03:43:17,680 [training] [INFO] training steps: 69600, Loss: 0.2645
2026-01-01 03:43:22,406 [training] [INFO] training steps: 69700, Loss: 0.2810
2026-01-01 03:43:27,134 [training] [INFO] training steps: 69800, Loss: 0.3279
2026-01-01 03:43:30,474 [training] [INFO] epoch 137 train loss:0.2851158344570328
2026-01-01 03:43:31,776 [training] [INFO] epoch 137 test loss:0.2747
2026-01-01 03:43:31,776 [training] [INFO] start training epochs 138
2026-01-01 03:43:33,713 [training] [INFO] training steps: 69900, Loss: 0.2878
2026-01-01 03:43:38,417 [training] [INFO] training steps: 70000, Loss: 0.3463
2026-01-01 03:43:43,122 [training] [INFO] training steps: 70100, Loss: 0.2661
2026-01-01 03:43:47,830 [training] [INFO] training steps: 70200, Loss: 0.2396
2026-01-01 03:43:52,541 [training] [INFO] training steps: 70300, Loss: 0.2515
2026-01-01 03:43:56,337 [training] [INFO] epoch 138 train loss:0.28092850505136974
2026-01-01 03:43:57,669 [training] [INFO] epoch 138 test loss:0.3092
2026-01-01 03:43:57,669 [training] [INFO] start training epochs 139
2026-01-01 03:43:59,147 [training] [INFO] training steps: 70400, Loss: 0.2700
2026-01-01 03:44:03,870 [training] [INFO] training steps: 70500, Loss: 0.2440
2026-01-01 03:44:08,585 [training] [INFO] training steps: 70600, Loss: 0.2805
2026-01-01 03:44:13,300 [training] [INFO] training steps: 70700, Loss: 0.3552
2026-01-01 03:44:18,013 [training] [INFO] training steps: 70800, Loss: 0.2199
2026-01-01 03:44:22,290 [training] [INFO] epoch 139 train loss:0.29055402801901686
2026-01-01 03:44:23,606 [training] [INFO] epoch 139 test loss:0.3176
2026-01-01 03:44:23,606 [training] [INFO] start training epochs 140
2026-01-01 03:44:24,626 [training] [INFO] training steps: 70900, Loss: 0.2331
2026-01-01 03:44:29,343 [training] [INFO] training steps: 71000, Loss: 0.2894
2026-01-01 03:44:34,058 [training] [INFO] training steps: 71100, Loss: 0.4581
2026-01-01 03:44:38,778 [training] [INFO] training steps: 71200, Loss: 0.3084
2026-01-01 03:44:43,497 [training] [INFO] training steps: 71300, Loss: 0.2231
2026-01-01 03:44:48,226 [training] [INFO] training steps: 71400, Loss: 0.2748
2026-01-01 03:44:48,249 [training] [INFO] epoch 140 train loss:0.2788344702592083
2026-01-01 03:44:49,545 [training] [INFO] epoch 140 test loss:0.3130
2026-01-01 03:44:49,545 [training] [INFO] start training epochs 141
2026-01-01 03:44:54,781 [training] [INFO] training steps: 71500, Loss: 0.2963
2026-01-01 03:44:59,480 [training] [INFO] training steps: 71600, Loss: 0.2830
2026-01-01 03:45:04,175 [training] [INFO] training steps: 71700, Loss: 0.2728
2026-01-01 03:45:08,872 [training] [INFO] training steps: 71800, Loss: 0.2711
2026-01-01 03:45:13,570 [training] [INFO] training steps: 71900, Loss: 0.2491
2026-01-01 03:45:14,068 [training] [INFO] epoch 141 train loss:0.2809498352455158
2026-01-01 03:45:15,393 [training] [INFO] epoch 141 test loss:0.3209
2026-01-01 03:45:15,394 [training] [INFO] start training epochs 142
2026-01-01 03:45:20,176 [training] [INFO] training steps: 72000, Loss: 0.2525
2026-01-01 03:45:24,895 [training] [INFO] training steps: 72100, Loss: 0.3669
2026-01-01 03:45:29,620 [training] [INFO] training steps: 72200, Loss: 0.2988
2026-01-01 03:45:34,335 [training] [INFO] training steps: 72300, Loss: 0.2512
2026-01-01 03:45:39,045 [training] [INFO] training steps: 72400, Loss: 0.3680
2026-01-01 03:45:40,020 [training] [INFO] epoch 142 train loss:0.27962830998733934
2026-01-01 03:45:41,317 [training] [INFO] epoch 142 test loss:0.3439
2026-01-01 03:45:41,318 [training] [INFO] start training epochs 143
2026-01-01 03:45:45,633 [training] [INFO] training steps: 72500, Loss: 0.2534
2026-01-01 03:45:50,340 [training] [INFO] training steps: 72600, Loss: 0.2469
2026-01-01 03:45:55,046 [training] [INFO] training steps: 72700, Loss: 0.3274
2026-01-01 03:45:59,747 [training] [INFO] training steps: 72800, Loss: 0.2472
2026-01-01 03:46:04,450 [training] [INFO] training steps: 72900, Loss: 0.2863
2026-01-01 03:46:05,896 [training] [INFO] epoch 143 train loss:0.2788933996768559
2026-01-01 03:46:07,197 [training] [INFO] epoch 143 test loss:0.3025
2026-01-01 03:46:07,197 [training] [INFO] start training epochs 144
2026-01-01 03:46:11,104 [training] [INFO] training steps: 73000, Loss: 0.4399
2026-01-01 03:46:15,800 [training] [INFO] training steps: 73100, Loss: 0.2908
2026-01-01 03:46:20,499 [training] [INFO] training steps: 73200, Loss: 0.2909
2026-01-01 03:46:25,200 [training] [INFO] training steps: 73300, Loss: 0.2413
2026-01-01 03:46:29,905 [training] [INFO] training steps: 73400, Loss: 0.2860
2026-01-01 03:46:31,816 [training] [INFO] epoch 144 train loss:0.277027652398044
2026-01-01 03:46:33,136 [training] [INFO] epoch 144 test loss:0.2764
2026-01-01 03:46:33,136 [training] [INFO] start training epochs 145
2026-01-01 03:46:36,538 [training] [INFO] training steps: 73500, Loss: 0.2726
2026-01-01 03:46:41,268 [training] [INFO] training steps: 73600, Loss: 0.2450
2026-01-01 03:46:45,996 [training] [INFO] training steps: 73700, Loss: 0.2521
2026-01-01 03:46:50,722 [training] [INFO] training steps: 73800, Loss: 0.2418
2026-01-01 03:46:55,450 [training] [INFO] training steps: 73900, Loss: 0.2519
2026-01-01 03:46:57,843 [training] [INFO] epoch 145 train loss:0.28192045396449517
2026-01-01 03:46:59,149 [training] [INFO] epoch 145 test loss:0.3065
2026-01-01 03:46:59,150 [training] [INFO] start training epochs 146
2026-01-01 03:47:02,004 [training] [INFO] training steps: 74000, Loss: 0.2604
2026-01-01 03:47:06,709 [training] [INFO] training steps: 74100, Loss: 0.3219
2026-01-01 03:47:11,425 [training] [INFO] training steps: 74200, Loss: 0.2608
2026-01-01 03:47:16,142 [training] [INFO] training steps: 74300, Loss: 0.2482
2026-01-01 03:47:20,855 [training] [INFO] training steps: 74400, Loss: 0.2535
2026-01-01 03:47:23,713 [training] [INFO] epoch 146 train loss:0.27508990636058883
2026-01-01 03:47:25,019 [training] [INFO] epoch 146 test loss:0.2759
2026-01-01 03:47:25,020 [training] [INFO] start training epochs 147
2026-01-01 03:47:27,452 [training] [INFO] training steps: 74500, Loss: 0.2591
2026-01-01 03:47:32,172 [training] [INFO] training steps: 74600, Loss: 0.2981
2026-01-01 03:47:36,893 [training] [INFO] training steps: 74700, Loss: 0.2359
2026-01-01 03:47:41,612 [training] [INFO] training steps: 74800, Loss: 0.2989
2026-01-01 03:47:46,329 [training] [INFO] training steps: 74900, Loss: 0.3176
2026-01-01 03:47:49,665 [training] [INFO] epoch 147 train loss:0.2795620107475449
2026-01-01 03:47:50,955 [training] [INFO] epoch 147 test loss:0.4213
2026-01-01 03:47:50,956 [training] [INFO] start training epochs 148
2026-01-01 03:47:52,960 [training] [INFO] training steps: 75000, Loss: 0.3612
2026-01-01 03:47:57,674 [training] [INFO] training steps: 75100, Loss: 0.3158
2026-01-01 03:48:02,388 [training] [INFO] training steps: 75200, Loss: 0.2461
2026-01-01 03:48:07,103 [training] [INFO] training steps: 75300, Loss: 0.2385
2026-01-01 03:48:11,818 [training] [INFO] training steps: 75400, Loss: 0.2271
2026-01-01 03:48:15,620 [training] [INFO] epoch 148 train loss:0.2776673922351762
2026-01-01 03:48:16,921 [training] [INFO] epoch 148 test loss:0.2900
2026-01-01 03:48:16,921 [training] [INFO] start training epochs 149
2026-01-01 03:48:18,440 [training] [INFO] training steps: 75500, Loss: 0.2601
2026-01-01 03:48:23,158 [training] [INFO] training steps: 75600, Loss: 0.2270
2026-01-01 03:48:27,875 [training] [INFO] training steps: 75700, Loss: 0.3635
2026-01-01 03:48:32,591 [training] [INFO] training steps: 75800, Loss: 0.2449
2026-01-01 03:48:37,304 [training] [INFO] training steps: 75900, Loss: 0.2919
2026-01-01 03:48:41,579 [training] [INFO] epoch 149 train loss:0.27418104541652344
2026-01-01 03:48:42,996 [training] [INFO] epoch 149 test loss:0.2774
2026-01-01 03:48:42,997 [training] [INFO] start training epochs 150
2026-01-01 03:48:43,981 [training] [INFO] training steps: 76000, Loss: 0.2715
2026-01-01 03:48:48,675 [training] [INFO] training steps: 76100, Loss: 0.2569
2026-01-01 03:48:53,367 [training] [INFO] training steps: 76200, Loss: 0.2306
2026-01-01 03:48:58,061 [training] [INFO] training steps: 76300, Loss: 0.2467
2026-01-01 03:49:02,769 [training] [INFO] training steps: 76400, Loss: 0.2831
2026-01-01 03:49:07,496 [training] [INFO] training steps: 76500, Loss: 0.3357
2026-01-01 03:49:07,519 [training] [INFO] epoch 150 train loss:0.27524084305646374
2026-01-01 03:49:09,101 [training] [INFO] epoch 150 test loss:0.3114
2026-01-01 03:49:09,101 [training] [INFO] training complete!
2026-01-01 03:49:09,357 [training] [INFO] training model saved
